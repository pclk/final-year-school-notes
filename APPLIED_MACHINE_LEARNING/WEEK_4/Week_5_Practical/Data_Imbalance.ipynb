{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Week 4: Imbalance Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(r'C:\\\\Users\\\\veronicali\\\\Downloads\\\\Handle-imbalanced-data-master\\\\Handle-imbalanced-data-master\\creditcard.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.Class.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# check the number of 1s and 0s\n",
        "count = data['Class'].value_counts()\n",
        "\n",
        "print('Fraudulent \"1\" :', count[1])\n",
        "print('Not Fraudulent \"0\":', count[0])\n",
        "\n",
        "# print the percentage of question where target == 1\n",
        "print(count[1]/count[0]* 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This show  that the data is highly imbalance. Only 0.17% of the data is belong to fraud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# plot the no of 1's and 0's\n",
        "g = sns.countplot(x='Class',data=data)\n",
        "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check for null values\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Respose and Target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "# check length of 1's and 0's\n",
        "one = np.where(y==1)\n",
        "zero = np.where(y==0)\n",
        "len(one[0]), len(zero[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Train_one = np.where(y_train==1)\n",
        "Train_zero = np.where(y_train==0)\n",
        "len(Train_one[0]), len(Train_zero[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Test_one = np.where(y_test==1)\n",
        "Test_zero = np.where(y_test==0)\n",
        "len(Test_one[0]), len(Test_zero[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit the model using Logitic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create the object\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model =  LogisticRegression()\n",
        "\n",
        "model.fit(x, y)\n",
        "\n",
        "y_predict = model.predict(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "accuracy_score(y_predict, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuray of 99.89% is achieved with this dataset. Let have a look of the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrix(y_predict, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc_auc_score(y_predict, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds=roc_curve(y_predict, y)\n",
        "plt.plot(fpr,tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f1_score(y_predict, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What can you conclude from the confusion matrix, ROC and F1 score?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Resampling Technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class count\n",
        "class_count_0, class_count_1 = data['Class'].value_counts()\n",
        "\n",
        "# divie class\n",
        "class_0 = data[data['Class'] == 0]\n",
        "class_1 = data[data['Class'] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the shape of the class\n",
        "print('class 0:', class_0.shape)\n",
        "print('\\nclass 1:', class_1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Random under sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_0_under = class_0.sample(class_count_1)\n",
        "\n",
        "test_under = pd.concat([class_0_under, class_1], axis=0)\n",
        "\n",
        "print(\"total class of 1 and 0:\\n\",test_under['Class'].value_counts())\n",
        "\n",
        "test_under['Class'].value_counts().plot(kind='bar', title='Count (target)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuray, Confusion matrix, ROC and F1 Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Random over sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_1_over = class_1.sample(class_count_0, replace=True)\n",
        "\n",
        "test_under = pd.concat([class_1_over, class_0], axis=0)\n",
        "\n",
        "# print the number of class count\n",
        "print('class count of 1 and 0:\\n', test_under['Class'].value_counts())\n",
        "\n",
        "# plot the count\n",
        "test_under['Class'].value_counts().plot(kind='bar', title='Count (target)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Balance data with imbalance learn module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import library\n",
        "import imblearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Random under-sampling with imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import library\n",
        "from collections import Counter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=42, replacement=True)\n",
        "\n",
        "# fit predictor and target varialbe\n",
        "x_rus, y_rus = rus.fit_resample(x, y)\n",
        "\n",
        "print('original dataset shape:', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_rus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Random over-sampling with imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import library\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "# fit predictor and target varaible\n",
        "x_ros, y_ros = ros.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape', Counter(y))\n",
        "print('Resample dataset shape', Counter(y_ros))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Under-sampling Tomek links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load library\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "tl = TomekLinks(sampling_strategy='majority')\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_tl, y_tl = tl.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape:', Counter(y))\n",
        "print('Resample dataset shape:', Counter(y_tl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Synthetic minority over-sampling technique (SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load library\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit target and predictor variable\n",
        "x_smote , y_smote = smote.fit_resample(x, y)\n",
        "\n",
        "print('Origianl dataset shape:', Counter(y))\n",
        "print('Resampple dataset shape:', Counter(y_smote))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. NearMiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import NearMiss\n",
        "\n",
        "nm = NearMiss()\n",
        "\n",
        "x_nm, y_nm = nm.fit_resample(x, y)\n",
        "\n",
        "print('Original dataset shape:', Counter(y))\n",
        "print('Resample dataset shape:', Counter(y_nm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let check out what is NearMiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. penalize algorithm (cost-sensitive training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# load library\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# we can add class_weight='balanced' to add panalize mistake\n",
        "svc_model = SVC(class_weight='balanced', probability=True)\n",
        "\n",
        "svc_model.fit(x_train, y_train)\n",
        "\n",
        "svc_predict = svc_model.predict(x_test)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let split the data into train and testing\n",
        "# Train the model using Logistic Regression\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Tree based algorithm\n",
        "\n",
        "While in every machine learning problem, it’s a good rule of thumb to try a variety of algorithms, it can be especially beneficial with imbalanced datasets.\n",
        "\n",
        "Decision trees frequently perform well on imbalanced data. In modern machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.) almost always outperform singular decision trees, so we’ll jump right into those:\n",
        "\n",
        "Tree base algorithm work by learning a hierarchy of if/else questions. This can force both classes to be addressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let Train the model using Random Forest\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "# fit the predictor and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let Train the model using XGBoost\n",
        "# Get the performance matrix: Accuracy, Confusion matrix, ROC and F1 Score, ROC Curve\n",
        "# fit the predictor and target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is the advantages and disadvantage of using under-sampling and over-sampling?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
