# Note
model: Cloze

## Text

Model Framework translates {{c1::ethical principles}} into {{c2::practical recommendations}} that organizations could adopt.

## Back Extra


# Note
model: Cloze

## Text

Section: Parts

The 4 parts of Model Framework are {{c1::Internal Governance structures & Measures}}, {{c2::Determining the level of human involvement in AI}}, {{c3::Operations Management}} and {{c4::Stakeholder Interaction & Communication}}

## Back Extra


# Note
model: Cloze

## Text

Section: Parts

{{c1::Internal Governance structure & Measures}} refers to {{c2::clear roles & responsibilities}} in organizations. {{c3::SOPs}} to {{c3::monitor}} and {{c3::manage}} {{c3::risks}}, and {{c4::Staff training}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Parts

{{c1::Determining the level of human involvement in AI-Augmented Decision-making}} refers to {{c2::appropriate degrees}} of {{c2::human involvement}}, and {{c3::minimizing}} the {{c3::risk}} of {{c3::harm}} to {{c3::individuals}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Parts

{{c1::Operations Management}} refers to {{c2::minimizing bias}} in {{c2::data}} and {{c2::model}} and a {{c3::risk-based approach}} to measures such as {{c4::explainability}}, {{c5::robustness}} and {{c6::regular tuning}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Parts

{{c1::Stakeholder Interaction & Communication}} refers to making {{c2::AI policies known}} to {{c2::users}}, allowing {{c3::users}} to {{c3::provide feedback}}, and making {{c4::communications understandable}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Not limited to

Model framework is not limited to {{c1::algorithms}}, {{c2::technology}}, {{c3::sectors}}, {{c4::scale}} and {{c5::business logic}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Not limited to

{{c1::Algorithm}} agnostic because it {{c2::doesn't focus on specific AI methodology}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Not limited to

{{c1::Technology}} agnostic because it {{c2::doesn't focus on specific systems, software, language or storage}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Not limited to

{{c1::Sector}} agnostic because it {{c2::serves as baseline set of considerations and measures}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Guiding principles

The decision\-making process should be {{c1::explainable}}, {{c2::transparent}} and {{c3::fair}} as much as possible. This helps build {{c4::trust}} and {{c5::confidence}} in AI.

## Back Extra


# Note
model: Cloze

## Text

Section: Guiding principles

AI solutions should be {{c1::human-centric}}, by {{c2::protecting}} the {{c2::interest}} of {{c2::human beings}}, including their {{c3::well-being}} and {{c4::safety}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Assumptions

Model framework aims to discuss {{c1::good data management practices}} in general.

## Back Extra


# Note
model: Cloze

## Text

Section: Assumptions

Model framework is mainly applicable to {{c1::machine learning models}}, not to {{c2::pure decision tree-driven AI models}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Assumptions

Model framework does not address the risk of {{c1::failure}} due to {{c1::cyber-attacks}}. 

## Back Extra


# Note
model: Cloze

## Text

Section: Assumptions

Model framework adoption does not {{c1::absolve}} organizations from {{c2::compliance}} from current {{c3::laws}} and {{c3::regulation}}. However, it could demonstrate {{c4::accountability}}. 

## Back Extra


# Note
model: Cloze

## Text

Section: Definition

{{c1::AI}} refers to a set of technologies that seek to {{c2::simulate human traits}}, to produce an {{c3::output}} or {{c3::decision}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Definition

{{c1::AI solution providers}} don't just develop for {{c2::B2C}}, but also {{c3::B2B2C}}

## Back Extra


# Note
model: Cloze

## Text

Section: Definition

{{c1::Organizations}} refer to {{c2::business entities}} that {{c3::adopt}} or {{c3::deploy}} {{c4::AI solutions}} in their operations.

## Back Extra


# Note
model: Cloze

## Text

Section: Definition

{{c1::Individuals}}, {{c2::consumers}} and {{c3::customers}} refers to persons whom {{c4::organizations}} intend to {{c5::supply AI products/services}} to, or have {{c6::purchased}} the {{c6::AI products/services}}

## Back Extra


# Note
model: Cloze

## Text

Section: Internal Governance Structures and Measures

The {{c1::appropriate personnel}} or {{c2::departments}} should be responsible for and oversight of the various stages and activities involved in {{c3::AI deployment}}  

## Back Extra


# Note
model: Cloze

## Text

Section: Internal Governance Structures and Measures

If necessary and possible, consider establishing a {{c1::coordinating body}}, having {{c2::relevant expertise}} and {{c3::proper representation}} from across the organisation.

## Back Extra


# Note
model: Cloze

## Text

Section: Internal Governance Structures and Measures

Personnel and/or departments having {{c1::internal AI governance functions}} should be fully aware of their {{c2::roles}} and {{c2::responsibilities}}, be {{c3::properly trained}}, and be provided with the {{c4::resources}} and {{c4::guidance}} needed for them to discharge their duties.

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

Someone in the organization should use any existing {{c1::risk management framework}} and applying {{c2::risk control measures}} to {{c3::assess}} and {{c3::manage}} the {{c3::risks}} of deploying AI, decide on the {{c4::appropriate level of human involvement}} in {{c4::AI-augmented decision-making}}, and manage the {{c5::AI model training}} and {{c5::selection process}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

When assessing the {{c1::risks of deploying AI}}, include any potential {{c2::adverse impact}} on the {{c3::individuals}} (e.g. who are most {{c4::vulnerable}}, how are they {{c5::impacted}}, how to {{c6::assess the scale of the impact}}, how to get {{c7::feedback}} from those impacted, etc.).

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

Someone should {{c1::maintain}}, {{c2::monitor}}, {{c3::document}} and {{c4::review}} the {{c5::AI models}} that have been deployed, with a view to taking {{c6::remediation measures}} where needed.

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

Someone should review {{c1::communications channels}} and {{c2::interactions}} with {{c3::stakeholders}} to provide {{c4::disclosure}} and {{c5::effective feedback channels}}

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

Someone should ensure {{c1::relevant staff}} dealing with {{c2::AI systems}} are {{c3::properly trained}}. 

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

Staff who are {{c1::working}} and {{c2::interacting}} directly with {{c3::AI models}} may need to be trained to {{c4::interpret AI model output}} and {{c5::decisions}} and to {{c6::detect}} and {{c7::manage bias}} in data. 

## Back Extra


# Note
model: Cloze

## Text

Section: Key roles & responsibilities

Staff whose work {{c1::indirectly deals}} with the {{c2::AI system}} should be trained to be at least {{c3::aware}} and {{c4::sensitive}} to the {{c5::benefits}}, {{c6::risks}} and {{c7::limitations}} when using AI, so that they know when to alert {{c8::subject-matter experts}} within their organisations

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should use reasonable efforts to ensure that the {{c1::datasets}} used for {{c2::AI model training}} are adequate for the intended purpose, and to assess and manage the risks of {{c3::inaccuracy}} or {{c4::bias}}, as well as reviewing {{c5::exceptions}} identified during model training. 

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should strive to understand the ways in which datasets may be {{c1::biased}} and address this in their {{c2::safety measures}} and {{c3::deployment strategies}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should establish {{c1::monitoring}} and {{c2::reporting systems}} as well as processes to ensure that the {{c3::appropriate level of management}} is aware of the {{c4::performance}} of and other issues relating to the deployed AI.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should include {{c1::autonomous monitoring}} to effectively scale {{c2::human oversight}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should design AI systems to report on the {{c1::confidence level}} of their predictions, 

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should design {{c1::explainability features}} that focus on why the AI model had a certain level of {{c2::confidence}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should ensure proper {{c1::knowledge transfer}} whenever there are changes in {{c2::key personnel}} involved in AI activities, to reduce the risk of gaps in {{c3::internal governance}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should review the {{c1::internal governance structure}} and {{c2::measures}} when there are significant changes to {{c3::organizational structure}} or {{c4::key personnel}} involved.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Management and Internal Controls

Organizations should {{c1::periodically review}} the internal governance structure and measures to ensure their continued {{c2::relevance}} and {{c3::effectiveness}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::Research Board}} consisting of the {{c2::Chief Technology Officer}}, the {{c3::Head of Labs}} and the {{c4::Chief Data Scientist}}, that approves the {{c5::AI development}} and {{c6::deployment}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::Chief Technology Officer}} oversees {{c2::four technical teams}} which consists of more than {{c3::100 employees}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::Research Team}}: performs {{c2::data analysis}}, {{c3::research}} and develop {{c4::Machine Learning models}} and {{c5::AI algorithms}}

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::Engineering Team}}: builds {{c2::software}}, {{c3::cloud services}} and {{c4::applications}}

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::Operation Team}}: deploys the {{c2::AI model}} and {{c3::upgrade platform}}

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::Delivery Team}}: engages with {{c2::operators}} and {{c3::integrate services}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

An {{c1::Architecture Steering Group}} consisting of the {{c2::Chief Technology Officer}}, {{c3::Chief Architect Officer}} and {{c4::lead engineers}}, ensures the {{c5::robustness}} of the {{c6::AI/ML models}} before {{c7::deployment}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

The {{c1::ASG}} has {{c2::bi-weekly meetings}} where the {{c3::research team}} shares its {{c4::findings}} on the {{c5::ML models}} and {{c6::AI algorithms}} (e.g. {{c7::data}}, {{c8::approach}} and {{c9::assumptions}}).

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

{{c1::PhD-level employees}} oversee the {{c2::AI development}} and {{c3::deployment process}}, and strive to implement {{c4::academic review standards}} for each {{c5::new feature development}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: CUJO AI

Employee ethical principles are to conduct {{c1::business ethically and honestly}} across all offices, base decisions on {{c2::integrity}}, {{c3::fairness}} and {{c4::sound judgment}}, not allow {{c5::unethical conduct}} from any {{c6::employee}} or {{c6::affiliate}} and never compromise {{c7::principles}} for {{c8::short-term gains}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: MASTERCARD

Established a {{c1::Governance Council}} chaired by {{c2::Executive VP of AI Center of Excellence}}, along with Chief {{c3::Data}} Officer, Chief {{c4::Privacy}} Officer, Chief {{c5::Information Security}} Officer, {{c6::data scientists}}, and {{c7::business representatives}}, to {{c8::review}} and {{c8::approve}} AI implementations that are {{c9::high risk}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: MASTERCARD

Chief {{c1::Data}} and Chief {{c2::Privacy}} Officer will ensure AI implementation proposal has {{c3::data fit for AI}}, {{c4::AI used for ethical purpose}}, {{c5::impacts to individuals are appropriate}}, and {{c6::potential harms are sufficiently mitigated}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: MASTERCARD

{{c1::Chief Information Security Officer}} will ensure that {{c2::security by design}} is implemented.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: MASTERCARD

{{c1::Data Science teams}} that build and implement AI maintain continuous dialogue with two offices: The {{c2::Data Office}} and The {{c3::Privacy Office}}. This ensures {{c4::continued information sharing about required governance}}, and {{c5::ongoing communication about the lifecycle of AI application implementations}}

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: MASTERCARD

Conducts {{c1::initial risk scoring}} by evaluating {{c2::alignment with corporate initiatives}}, {{c3::data types and sources}}, and {{c4::impact on individuals}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Examples

Sub-section: MASTERCARD

Identify {{c1::potential mitigations}} to reduce level of risk from {{c2::collecting data}}, or {{c3::potential biases}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Determining the Level of Human Involvement in AI-Augmented Decision-Making

{{c1::Commercial objectives}} should be weighed against {{c2::AI risks}} in decision\-making. When weighing AI risks, it should be guided by {{c3::corporate values}}, which should reflect {{c4::societal norms of the country}}. {{c5::Multi national companies}} should consider {{c6::differences in societal norms}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Determining the Level of Human Involvement in AI-Augmented Decision-Making

{{c1::Risk levels}} vary based on {{c2::where AI is deployed}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Determining the Level of Human Involvement in AI-Augmented Decision-Making

{{c1::Human-in-the-loop}} suggests that {{c2::human oversight is active and involved}}, with the {{c3::human retaining full control}} and the {{c4::AI only providing recommendations or input}}. Decisions cannot be exercised without {{c5::affirmative actions by the human}}, such as a {{c6::human command to proceed}} with a given decision. However, this requires the AI to provide {{c7::enough information for human to make an informed decision}}, like the {{c8::factors considered}}, {{c9::weights of the factors}}, {{c10::correlations}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Determining the Level of Human Involvement in AI-Augmented Decision-Making

{{c1::Human-out-of-the-loop}} suggests that there is {{c2::no human oversight}} over the execution of decisions, and the {{c3::AI system has full control}} without the {{c4::option of human override}}. For example, {{c5::product recommendation engine}}, {{c6::airline demand forecaster}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Determining the Level of Human Involvement in AI-Augmented Decision-Making

{{c1::Human-over-the-loop}} or {{c2::human-on-the-loop}} suggests that human oversight is involved to the extent that the {{c3::human is in a monitoring or supervisory role}}. Human can {{c4::take over control}} when the Al model encounters {{c5::unexpected or undesirable events}}. For example, {{c6::driver controlling GPS navigation system with route-planning}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

The {{c1::risk assessment matrix}} is structured along two axes. The {{c2::probability}} and {{c3::severity of harm}} as a result of the decision made impacting the user.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: Online Retail Product Recommendations

Using {{c1::AI}} to automate the recommendation of food products to individuals is a {{c2::low probability, low severity risk assessment}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: Online Retail Product Recommendations

{{c1::Low probability and severity assessment}} points to {{c2::human-out-of-the-loop}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: Online Retail Product Recommendations

The {{c1::probability of harm}} depends on the {{c2::efficiency}} and {{c3::efficacy}} of the AI solution.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: Online Retail Product Recommendations

Regularly {{c1::review}} and {{c2::re-assess}} the probability and severity of harm as {{c3::societal norms}} evolve.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: SUADE LABS

The {{c1::probability of harm}} depends on {{c2::degree of domain knowledge}} required to accurately interpret the results of AI.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: SUADE LABS

The {{c1::severity of harm}} depends on the {{c2::cost of non-compliance}} to regulation.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: SUADE LABS

Using {{c1::AI}} to generate required regulatory data is a {{c2::high probability, high severity risk assessment}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: SUADE LABS

{{c1::High probability and severity assessment}} points to {{c2::human-in-the-loop}}. Should also favour {{c3::false positive}} over {{c4::false negatives}}. Though if {{c5::user research}} indicates opposing preference, allow the option to tune to personal preference.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: GRAB

In risk assessment, the {{c1::feasibility}} of the {{c2::human-in-the-loop}} should be considered.

## Back Extra


# Note
model: Cloze

## Text

Section: Risk Assessment Matrix

Sub-section: GRAB

Using {{c1::AI}} to optimize trip allocations is a {{c2::low probability, low severity risk assessment}}.

## Back Extra


# Note
model: Cloze

## Text

{{c1::Datasets}} used for building models may come from {{c2::multiple sources}}, and could include both {{c3::personal}} and {{c4::non-personal data}}.

## Back Extra


# Note
model: Cloze

## Text

The {{c1::quality}} and {{c2::selection}} of data from each of these sources are critical to the {{c3::success}} of an AI solution.

## Back Extra


# Note
model: Cloze

## Text

If a model is built using {{c1::biased}}, {{c2::inaccurate}} or {{c3::non-representative data}}, the risks of {{c4::unintended discriminatory decisions}} from the model will increase.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Understanding the {{c1::lineage of data}} means knowing where the {{c2::data originally came from}}, how it was {{c3::collected}}, {{c4::curated}}, and {{c5::moved within the organisation}}, and how its {{c6::accuracy}} is maintained over time.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

The 3 types of data lineage are {{c1::Backward data lineage}}, {{c2::Forward data lineage}} and {{c3::End-to-end data lineage}}

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

{{c1::Backward data lineage}} looks at the data from its {{c2::end-use}} and {{c3::backdating it to its source}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

{{c1::Forward data lineage}} begins at the {{c2::data's source}} and follows it through to its {{c3::end-use}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

{{c1::End-to-end data lineage}} combines the two and looks at the entire solution from both the {{c2::data's source to its end-use}} and from its {{c3::end-use to its source}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Keeping a {{c1::data provenance record}} allows an organisation to {{c2::ascertain the quality of the data}} based on its {{c3::origin}} and {{c4::subsequent transformation}}, {{c5::trace potential sources of errors}}, {{c6::update data}}, and {{c7::attribute data to their sources}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

If the {{c1::origin of data}} is difficult to establish, the organization needs to {{c2::reconsider the risks}} of using such data.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

{{c1::Good data accountability practices}} include {{c2::understanding the lineage of data}}, {{c3::ensuring data quality}}, {{c4::minimizing bias}}, {{c5::dataset splitting}}, and {{c6::periodic reviews and updates}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

The {{c1::accuracy}} of the dataset, in terms of how well the {{c2::values}} in the dataset match the {{c3::true characteristics}} of the entities described by the dataset;

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

The {{c1::completeness}} of the dataset, both in terms of {{c2::attributes}} and {{c3::items}};

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

The {{c1::veracity}} of the dataset, which refers to how {{c2::credible}} the data is, including whether the data originated from a {{c3::reliable source}};

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

How {{c1::recently}} the dataset was {{c2::compiled}} or {{c3::updated}};

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

The {{c1::relevance}} of the dataset and the {{c2::context for data collection}}, as it may affect the {{c3::interpretation}} and {{c4::reliance}} on the data for the intended purpose;

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

The {{c1::integrity}} of the dataset that has been joined from multiple datasets, which refers to how well {{c2::extraction}} and {{c3::transformation}} have been performed;

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

The {{c1::usability}} of the dataset, including how well the dataset is {{c2::structured}} in a {{c3::machine-understandable form}};

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Ensuring data quality

{{c1::Human interventions}} (e.g. if any human has {{c2::filtered}}, {{c3::applied labels}}, or {{c4::edited}} the data).

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

The {{c1::2 common types of bias in data}} include {{c2::Selection bias}} and {{c3::Measurement bias}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

{{c1::Selection bias}} occurs when the {{c2::training data is not representative of the actual environment the model functions in}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

The {{c1::2 common examples of selection bias}} include {{c2::omission bias}} and {{c3::stereotype bias}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

{{c1::Omission bias}} describes the {{c2::omission of certain characteristics from the dataset}}. 

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

An example of {{c1::Omission bias}} is a {{c2::dataset consisting only of Asian faces but used for a population that includes non-Asians}}. 

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

An example of {{c1::stereotype bias}} is a {{c2::dataset of vehicle types representing types of transportation available but data collection was within CBD weighted to cars, buses and motorcycles but not bicycles}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

{{c1::Measurement bias}} occurs when the {{c2::data collection device causes the data to be systematically skewed in a particular direction}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Identification

An example of {{c1::Measurement bias}} is a {{c2::pictures with camera that can't see a colour}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Mitigation

Have a {{c1::heterogeneous dataset}}, collecting data from a {{c2::variety of reliable sources}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Bias in data > Mitigation

Avoid {{c1::premature removal of data attributes}} to allow for {{c2::identifying and addressing of bias}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Dataset splitting

{{c1::Different datasets}} are required for {{c2::training}}, {{c3::testing}}, and {{c4::validation}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Dataset splitting

The model could also be checked for {{c1::systematic bias}} by {{c2::testing it on different demographic groups}} to observe whether any groups are being {{c3::systematically advantaged or disadvantaged}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Dataset splitting

If can't test model on different demographic groups, maybe because {{c1::small dataset}} or {{c2::transfer learning}}, then be {{c3::aware of systematic bias}} and place {{c4::appropriate safeguards}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Periodic reviews and updates

{{c1::Dataset}} with {{c2::new updated input data}} obtained from production should be checked for {{c3::potential bias}} if it has already gone through the model. 

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Periodic reviews and updates

{{c1::Review datasets periodically}} to ensure {{c2::accuracy}}, {{c3::quality}}, {{c4::currency}}, {{c5::relevance}} and {{c6::reliability}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > SUADE LABS

{{c1::Obtain and update regulatory data}} only from {{c2::relevant regulators}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > SUADE LABS

{{c1::Tag datasets}} with {{c2::metadata}} to {{c3::trace to data source}} when needed, such as where {{c4::inconsistencies}} are found.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > SUADE LABS

{{c1::Document and store}} which {{c2::datasets}} were used in an {{c3::AI model}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > SUADE LABS

Use as many {{c1::individuals}} as practicable to {{c2::tag data}} to reduce {{c3::tagger bias}}. 

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > SUADE LABS

Develop a {{c1::tagging system}} to facilitate the {{c2::annotation of data}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > SUADE LABS

{{c1::Verify}} that the {{c2::data schema}} accurately represents the {{c3::data from the source}}, to ensure there are no {{c4::errors}} in factors such as the {{c5::data's formatting and content}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > PYMETRICS:

{{c1::Validate}} generated {{c2::training data}} with your {{c3::client's team}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > PYMETRICS:

Use {{c1::objective features}} based on {{c2::established research}} that are generally {{c3::stable across demographic groups}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > PYMETRICS:

Do not {{c1::disadvantage people}} on the basis of their {{c2::demographic features}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > PYMETRICS:

The {{c1::US' Equal Employment Opportunity Commission}} states that the {{c2::selection rate}} for any {{c3::legally protected group}} must be at least {{c4::80%}} of the {{c5::selection rate}} for the {{c6::majority group}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > PYMETRICS:

An example of the US' Equal Employment Opportunity Commission is if {{c1::100 men}} and {{c2::100 women}} are screened and {{c3::50 men}} are selected, at least {{c4::40 women}} must be selected.

## Back Extra


# Note
model: Cloze

## Text

Section: Good data accountability practices

Sub-section: Examples > PYMETRICS:

After {{c1::model deployment}}, test on {{c2::real individuals}} for {{c3::adverse impact}}, and {{c4::revisit}} for {{c5::long-term impacts}} of the {{c6::AI predictions}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

The {{c1::5 best practices for Algorithms and Models}} are {{c2::Explainability}}, {{c3::Repeatability}}, {{c4::Robustness}}, {{c5::Regular Tuning}} and {{c6::Traceability}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

{{c1::Explainability}} is achieved by explaining how {{c2::deployed AI models' algorithms function}} and how the {{c3::model predictions are utilized to make decisions}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

The purpose of being able to {{c1::explain predictions made by AI}} is to build {{c2::understanding}} and {{c3::trust}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

An algorithm deployed in an AI solution is said to be {{c1::explainable}} if {{c2::how it functions}} and {{c3::how it arrives at a particular prediction}} can be explained.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

When an {{c1::algorithm cannot be explained}}, understanding and trust can still be built by explaining how {{c2::predictions play a role in the decision-making process}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

{{c1::Documenting}} how the {{c2::model training}} and {{c3::selection processes}} are conducted, the {{c4::reasons for which decisions are made}}, and {{c5::measures taken to address identified risks}} will enable the organisation to provide an account of the decisions.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

When using {{c1::Automated Machined Learning tools}}, organizations should consider the {{c2::transparency}}, {{c3::explainability}} and {{c4::traceability}} of the automated machine learning approach.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

Include {{c1::design}} (why certain decisions were made) and {{c2::expected behaviour}} as {{c3::product labels}} and {{c4::documentations}} for accountability and understanding.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

If {{c1::AI system}} was obtained from {{c2::3rd-party AI solution provider}}, request assistance to explain how the solution functions.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Explainability

Use {{c1::supplementary explanation tools}} to help make {{c2::underlying rationale of AI output}} more {{c3::interpretable to users}}, and improve {{c4::explainability}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

{{c1::Repeatability}} refers to the ability to {{c2::consistently perform an action}} or {{c3::make a decision}}, given the {{c4::same scenario}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

While {{c1::repeatability}} (of results) is not equivalent to {{c2::explainability}} (of algorithm), some degree of {{c3::assurance of consistency}} in performance could provide AI users with a larger degree of {{c4::confidence}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

Conducting {{c1::repeatability assessments}} for {{c2::commercial deployments}} in {{c3::live environments}} to ensure that deployments are repeatable.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

{{c1::Counterfactual fairness testing}} ensures that a model's decisions are the same in both the {{c2::real world}} and in a {{c3::counterfactual world}} where {{c4::attributes deemed sensitive}} (such as {{c5::race}} or {{c6::gender}}) are altered.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

Assessing how {{c1::exceptions}} can be identified and handled when {{c2::decisions are not repeatable}}, e.g. when {{c3::randomness}} has been introduced by design.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

Helpful if {{c1::AI models}} can highlight {{c2::situations with new variables}} previously not considered to a human.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Repeatability

Identifying and accounting for {{c1::changes over time}} to ensure that {{c2::models trained on time-sensitive data}} remain relevant.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Robustness

Ensuring that {{c1::deployed models}} are sufficiently {{c2::robust}} will contribute towards building {{c3::trust}} in the {{c4::AI system}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Robustness

{{c1::Robustness}} refers to the ability of a computer system to {{c2::cope with errors}} during {{c3::execution}} and {{c4::erroneous input}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Robustness

{{c1::Robustness}} is assessed by the degree to which a system or component can {{c2::function correctly}} in the presence of {{c3::invalid input}} or {{c4::stressful environmental conditions}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Robustness

{{c1::Continual learning}} is when models {{c2::changes its learned parameters}} after being {{c3::deployed into production}}.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Robustness

{{c1::Continual learning}} can be {{c2::unpredictable}} since the {{c3::input data}} has changed.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Regular tuning

Establish an {{c1::internal process}} to perform {{c2::regular model tuning}} to ensure that {{c3::deployed models}} cater for {{c4::changes to customer behaviour}} over time.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Regular tuning

{{c1::Tune models}} when {{c2::commercial objectives}}, {{c3::risks}} or {{c4::corporate values}} change.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

{{c1::AI-augmented decisions}} are {{c2::traceable}} if {{c3::decisions of the model}} are documented.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

{{c1::Model training}} is traceable if {{c2::dataset}} and {{c3::training process}} of AI model are documented.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

{{c1::Traceability}} facilitates {{c2::transparency}} and {{c3::explainability}}, and also can be used for {{c4::troubleshooting}} or a {{c5::source of input data}}

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

A {{c1::black box recorder}} captures all {{c2::input data streams}}. For example, tracking a {{c3::car's position}}, {{c4::technical problems}} and {{c5::requests to take over control}} of the car.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

To promote {{c1::traceability}}, build an {{c2::audit trail}} to document {{c3::model training}} and {{c4::AI-augmented decision}}, implementing a {{c5::black box recorder}}, and storing data appropriately. 

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

{{c1::Traceability measures}} may lead to a {{c2::large volume of activity data}}. Therefore organizations should reconsider prioritizing what {{c3::product features}} require traceability, and which {{c4::traceability measure}} to apply.

## Back Extra


# Note
model: Cloze

## Text

Section: Best practices for Algorithms and Models

Sub-section: Traceability

Organization considering the implementation of {{c1::traceability}} should base it on {{c2::risk assessment matrix}}, {{c3::length of time the model has been used}}, and {{c4::regulatory needs}} of their industry.

## Back Extra


