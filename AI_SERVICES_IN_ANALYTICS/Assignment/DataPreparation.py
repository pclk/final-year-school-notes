r"""°°°
![nyp.jpg](attachment:nyp.jpg)
°°°"""
# |%%--%%| <PlteIgn7Ko|IEy4wnPs4T>
r"""°°°
# IT3386 - AI Services in Analytics

BEFORE PROCEEDING, DR BRANDON:

Let's understand what the files and folders mean.

/people_ladder
> This is the original image dataset file

/people_ladder_copy
> This is the image dataset file that has been worked on. It has missing files compared to the original image dataset file, because some of the operations in these notebooks include moving of these file pairs.

/predictions_output
> This is the predictions made by the model with the drawn bounding boxes.

/test
> This is the directory where images are selected at random for testing the deployed model

/unwanted
> This is the unwanted directory, where DataPreparation.ipynb's VOC Processor has moved it here for the various reasons mentioned.

/media
> This is the directory of media shots, which were used to create the final video

AIA.mp4
> This is the 10-11 min video describing the entire project.

annotations.csv
> This is the generated csv file for google cloud.

business_case.pdf
> This is the business case slides used to present for the video

predictions.json
> This is the preditions generated by the deployed model.

script.md
> This is the script used to record notebook recordings.

VOC.jpg
> This is the image to describe and explain VOCProcessor in a flowchart format.


°°°"""
# |%%--%%| <IEy4wnPs4T|YW1LOlp294>
r"""°°°
## 1. Business Case

Refer to the business_case.pdf to supplement.
°°°"""
# |%%--%%| <YW1LOlp294|wncJVRKZz5>
r"""°°°
## **Precision Safety Annotation: A Computer Vision Approach to Workplace Risk Assessment**

In the realm of workplace safety, even the simplest technological intervention can yield significant insights. Our computer vision model, designed to annotate a single image with precise bounding boxes identifying ladders and people, offers a targeted solution to workplace safety documentation and risk assessment.

### **Core Functionality**
- Detect and draw bounding boxes around Persons and Ladders

### **Business Value Proposition**

1. Incident Documentation

> The model provides an objective, instantaneous method of documenting workplace positioning during potentially risky activities. By creating a visual record that precisely identifies ladder placement and worker location, organizations can:
- Capture exact moment of potential safety risks
- Create clear, unambiguous visual evidence
- Support post-incident analysis

2. Insurance and Liability Management

- Generate precise visual documentation
- Create objective evidence for insurance claims
- Support detailed incident investigations
- Provide clear spatial context in accident reports

### **Practical Applications**

1. Construction Site Management
- Snapshot safety compliance verification
- Document worker positioning
- Create quick visual safety logs

2. Maintenance and Inspection
- Record worker location during elevated tasks
- Create visual documentation of work processes
- Support retrospective safety analysis

3. Training and Safety Protocols
- Use annotated images as training materials
- Demonstrate correct vs. incorrect positioning (note that this model can only draw bounding boxes of the identified Person and Ladder, but cannot determine whether the positioning is safe. That would have to be done by humans, or a further annotating and labelling process.)

### **Limitations and Considerations**
- Limited to detection, not prevention

### **Unique Value Proposition**
The model transforms a simple image into a detailed safety insights tool, offering organizations an affordable, straightforward approach to visual safety documentation.

### **Cost-Benefit Analysis**
- Development Cost: Low
    - Data is available online
    - The process to annotate them aren't complex, with only two labels to consider
- Implementation Complexity: Minimal
    - Using AutoML, we can call the deployment API to retrieve the results. This can easily be done, implemented on a website.
- Potential Risk Reduction: Significant
    - From having no documentation images to having detailed, personalized and exact documentation, and bounding boxes for analysis, there is a huge improvement to the analysis of dangerous work conditions.

### **Conclusion**
In workplace safety, sometimes the most effective solutions are elegantly simple. Our computer vision model demonstrates how even a basic technological approach can provide valuable insights into workplace positioning and potential risks.

The power lies not in complex prevention mechanisms, but in creating clear, objective visual documentation that can support safer work practices, inform training, and provide critical evidence when needed.
°°°"""
# |%%--%%| <wncJVRKZz5|zeTUewBSwh>
r"""°°°
## 2.1 Data Preparation

Main Tasks (refer to assignment brief for a complete list of tasks)
- Prepare images according to project criteria
- Perform image pre-processing
- Draw bounding boxes
- ...
- Prepare Annotation file
- Check bounding boxes of normalised vertices
- Ensure local directory contains images and annotation file
°°°"""
# |%%--%%| <zeTUewBSwh|c8xhZsHnAO>
r"""°°°
## This class "VOCProcessor" has been brought to you by OpenAI o1-preview, Claude 3.5 sonnet, and me.

### What does it do?
The code represents a sophisticated image annotation processing system designed to handle Visual Object Classes (VOC) format data.

At its core, it's built to process and validate images that contain both ladders and people, with a strong emphasis on data quality and consistency.

The processing begins with the process_files function, which serves as the main conductor of operations. This function scans through all XML files in the specified directory, managing the workflow while continuously monitoring the annotation limit. It's responsible for initiating the validation and processing sequence for each file it encounters.

Each file then moves through the check_file_issues function, which implements a thorough validation protocol. This step verifies multiple aspects of the file: it confirms the existence of a matching JPG file, checks for any empty annotations, ensures both "Person" and "Ladder" labels are present, validates the image resolution (specifically looking for 640x640 dimensions), and initiates the bounding box validation process. Any issues discovered during this phase are carefully documented.

For files that make it past the initial checks, the correct_bbox_coordinates function takes over. This function focuses on fixing minor bounding box issues that might exist in the file. It works by parsing the XML file, examining the image dimensions, and reviewing each bounding box definition. When possible, it makes automatic corrections, such as adjusting coordinates from 641 to 640, and saves these corrections back to the XML file.

The check_bbox_validity function performs a detailed examination of each bounding box's coordinates. It verifies that all coordinates fall within proper image boundaries, ensures that minimum values are less than maximum values, and checks for any negative values. This function is crucial for maintaining data integrity and returns both validation status and any necessary corrections.
When issues are discovered, the move_to_unwanted function manages the rejection process. It determines the primary reason for rejection, handles the physical moving of both XML and JPG files to their appropriate rejection directories, and maintains detailed logs explaining why each file was rejected. This creates a clear audit trail for rejected files.

Files that successfully pass all validations are processed by the process_xml function. This step extracts all relevant annotation information, normalizes the coordinates to standard values, creates properly formatted annotation entries, and adds these entries to the main annotation list for final processing.

After all files have been processed, the create_csv function takes over. It collects all the validated annotations, organizes them into a structured format, and generates a standardized CSV file. This output file follows specific formatting requirements to ensure compatibility with machine learning pipelines and other data processing systems.

The final step is handled by print_summary, which generates a comprehensive processing report. This report includes vital statistics such as the total number of processed images, the count of collected annotations, progress towards the annotation limit, and a detailed breakdown of rejected files by category. This summary provides valuable insights into the entire processing operation and its outcomes.

![image.png](attachment:0bd69c25-b764-427a-ae71-1c00e5298068.png)
°°°"""
# |%%--%%| <c8xhZsHnAO|L6xsoqj7eE>

import os
import shutil
import xml.etree.ElementTree as ET
from concurrent.futures import ThreadPoolExecutor
from enum import Enum
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd

# categorizes various reasons why images might be rejected from the dataset
class UnwantedReason(Enum):
    MISSING_PERSON = "missing_person"
    MISSING_LADDER = "missing_ladder"
    UNPAIRED_FILE = "unpaired_file"
    EMPTY_ANNOTATION = "empty_annotation"
    INVALID_RESOLUTION = "invalid_resolution"
    CORRUPTED_FILE = "corrupted_file"
    INVALID_BBOX = "invalid_bbox"


class VOCProcessor:
    def __init__(self, voc_filepath: str, annotation_limit: int = 300):
        self.voc_path = Path(voc_filepath)
        self.unwanted_base = Path("./unwanted")
        self.processed_dir = Path("./no_name/train")
        self.annotations: List[List] = []
        self.annotation_limit = annotation_limit
        self.annotation_count = 0  # Track total annotations

        # Create necessary directories for each reason
        self.unwanted_dirs = {}
        for reason in UnwantedReason:
            path = self.unwanted_base / reason.value
            path.mkdir(parents=True, exist_ok=True)
            self.unwanted_dirs[reason] = path

        self.processed_dir.mkdir(parents=True, exist_ok=True)

    # Main function
    def process_files(self):
        xml_files = list(self.voc_path.glob("*.xml"))

        print(f"Processing files (limit: {self.annotation_limit} annotations)...")

        for xml_path in xml_files:
            # Check for issues
            issues = self.check_file_issues(xml_path)
            if self.annotation_count >= self.annotation_limit:
                print(f"\nReached annotation limit ({self.annotation_limit})")
                break

            if issues:
                # Move to unwanted with reasons
                self.move_to_unwanted(xml_path, issues)
            else:
                # Process valid file, taking into account the annotation_limit
                is_valid, annotations = self.process_xml(xml_path)
                if is_valid:
                    new_total = self.annotation_count + len(annotations)
                    if new_total > self.annotation_limit:
                        print(
                            f"\nSkipping {xml_path.name} as it would exceed annotation limit"
                        )
                        continue
                    self.annotations.extend(annotations)
                    self.annotation_count = new_total
                    # Move to processed directory
                    jpg_path = xml_path.with_suffix(".jpg")
                    shutil.move(str(jpg_path), str(self.processed_dir / jpg_path.name))

    def check_file_issues(self, xml_path: Path) -> List[Tuple[UnwantedReason, str]]:
        """
        Check for various issues in the XML and corresponding JPG file.
        - check that xml has a .jpg with the same name, aka a paired jpg
        - check that xml has annotations
        - check that xml has both Person and Ladder labels
        - check that jpg has 640x640 resolution
        - check that xml's bounding box is valid (see def correct_bbox_coordinates)
        
        Returns: List of tuples (UnwantedReason, detailed_message)
        """
        issues = []

        try:
            # Check for paired jpg
            jpg_path = xml_path.with_suffix(".jpg")
            if not jpg_path.exists():
                issues.append(
                    (UnwantedReason.UNPAIRED_FILE, f"Missing JPG file: {jpg_path.name}")
                )
                return issues

            # Parse XML
            tree = ET.parse(xml_path)
            root = tree.getroot()

            # Check for empty annotations (no objects)
            objects = root.findall("object")
            if not objects:
                issues.append(
                    (UnwantedReason.EMPTY_ANNOTATION, "No object tags found in XML")
                )
                return issues

            # Check for required labels
            labels = set(obj.find("name").text for obj in objects)
            if "Person" not in labels:
                issues.append(
                    (
                        UnwantedReason.MISSING_PERSON,
                        f"Missing 'Person' label. Found labels: {labels}",
                    )
                )
            if "Ladder" not in labels:
                issues.append(
                    (
                        UnwantedReason.MISSING_LADDER,
                        f"Missing 'Ladder' label. Found labels: {labels}",
                    )
                )

            # Check image resolution
            size_elem = root.find("size")
            if size_elem is not None:
                width = float(size_elem.find("width").text)
                height = float(size_elem.find("height").text)
                if width != 640 or height != 640:
                    issues.append(
                        (
                            UnwantedReason.INVALID_RESOLUTION,
                            f"Invalid resolution: {width}x{height}, expected 640x640",
                        )
                    )

            # Check and correct bounding box validity
            self.correct_bbox_coordinates(xml_path)

            # Recheck after corrections
            tree = ET.parse(xml_path)
            root = tree.getroot()
            size_elem = root.find("size")
            width = float(size_elem.find("width").text)
            height = float(size_elem.find("height").text)

            for obj in root.findall("object"):
                bbox = obj.find("bndbox")
                if bbox is not None:
                    is_valid, error_msg, _, _ = self.check_bbox_validity(
                        bbox, width, height
                    )
                    if not is_valid:
                        label = obj.find("name").text
                        detailed_msg = f"Invalid bbox for {label}: {error_msg}"
                        issues.append((UnwantedReason.INVALID_BBOX, detailed_msg))
                        break

        except ET.ParseError as e:
            issues.append(
                (UnwantedReason.CORRUPTED_FILE, f"XML parsing error: {str(e)}")
            )
        except Exception as e:
            issues.append(
                (UnwantedReason.CORRUPTED_FILE, f"Unexpected error: {str(e)}")
            )

        return issues

    def correct_bbox_coordinates(self, xml_path: Path):
        """
        Correct bbox coordinates in XML file if needed.
        Will correct if check_bbox_validity (see def) returns need corrections.
        """
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()

            size_elem = root.find("size")
            width = float(size_elem.find("width").text)
            height = float(size_elem.find("height").text)

            corrections_made = False

            for obj in root.findall("object"):
                bbox = obj.find("bndbox")
                if bbox is not None:
                    is_valid, msg, needs_correction, corrected_values = (
                        self.check_bbox_validity(bbox, width, height)
                    )

                    if needs_correction:
                        corrections_made = True
                        for coord, value in corrected_values.items():
                            bbox.find(coord).text = str(int(value))

            if corrections_made:
                tree.write(xml_path)

            return

        except Exception as e:
            print(f"Error correcting coordinates in {xml_path}: {str(e)}")
            return

    def check_bbox_validity(
        self, bbox, width: float, height: float
    ) -> Tuple[bool, str, bool, dict]:
        """
        Check bbox coordinates validity and return detailed error message.
        Returns: (is_valid, error_message, needs_correction, corrected_values)
        """
        xmin = float(bbox.find("xmin").text)
        ymin = float(bbox.find("ymin").text)
        xmax = float(bbox.find("xmax").text)
        ymax = float(bbox.find("ymax").text)

        needs_correction = False
        corrected_values = {}

        # Correct 641 to 640
        if xmax == 641:
            xmax = 640
            needs_correction = True
            corrected_values["xmax"] = 640

        if ymax == 641:
            ymax = 640
            needs_correction = True
            corrected_values["ymax"] = 640

        # Check each condition separately with detailed messages
        if xmin < 0:
            return False, f"xmin ({xmin}) < 0", False, {}
        if ymin < 0:
            return False, f"ymin ({ymin}) < 0", False, {}
        if xmax > width and xmax != 640:  # Allow 640
            return False, f"xmax ({xmax}) > width ({width})", False, {}
        if ymax > height and ymax != 640:  # Allow 640
            return False, f"ymax ({ymax}) > height ({height})", False, {}
        if xmin >= xmax:
            return False, f"xmin ({xmin}) >= xmax ({xmax})", False, {}
        if ymin >= ymax:
            return False, f"ymin ({ymin}) >= ymax ({ymax})", False, {}

        return True, "", needs_correction, corrected_values

    
    def move_to_unwanted(
        self, file_path: Path, issues: List[Tuple[UnwantedReason, str]]
    ):
        """
        Move and log unwanted files into the categorized issue directory.
        """
        if not issues:
            return

        # Use the first reason as the primary reason
        primary_reason, detailed_msg = issues[0]
        target_dir = self.unwanted_dirs[primary_reason]

        try:
            # Move files
            if file_path.suffix == ".xml":
                jpg_path = file_path.with_suffix(".jpg")
                if jpg_path.exists():
                    shutil.move(str(jpg_path), str(target_dir / jpg_path.name))
            shutil.move(str(file_path), str(target_dir / file_path.name))

            # Log with detailed messages
            with open(self.unwanted_base / "unwanted_reasons.log", "a") as f:
                f.write(f"{file_path.name}:\n")
                for reason, msg in issues:
                    f.write(f"  - {reason.value}: {msg}\n")
                f.write("\n")

        except Exception as e:
            print(f"Error moving {file_path}: {str(e)}")
    
    def process_xml(self, xml_path: Path) -> Tuple[bool, List]:
        """
        Process a single XML file and return annotations if valid.
        Valid files must contain BOTH 'Ladder' AND 'Person' labels.
        
        Also normalizes bounding box coordinates and generates the
        annotations in the csv format required by google.
        
        Returns: (is_valid, annotations_list)
        """
        try:
            tree = ET.parse(xml_path)
            root = tree.getroot()

            # Get all object labels in the XML
            labels = set(obj.find("name").text for obj in root.findall("object"))

            # Check if both required labels are present
            if not {"Ladder", "Person"}.issubset(labels):
                return False, []

            filename = root.find("filename").text
            width = float(root.find("size/width").text)
            height = float(root.find("size/height").text)

            file_annotations = []
            image_path = f"gs://i220342h-3386-aip/train/{filename}"

            # Process all objects in the XML
            for obj in root.findall("object"):
                bbox = obj.find("bndbox")

                # Normalize coordinates with single division operation
                x_min = round(float(bbox.find("xmin").text) / width, 9)
                y_min = round(float(bbox.find("ymin").text) / height, 9)
                x_max = round(float(bbox.find("xmax").text) / width, 9)
                y_max = round(float(bbox.find("ymax").text) / height, 9)

                file_annotations.append(
                    [
                        image_path,
                        obj.find("name").text,
                        x_min,
                        y_min,
                        "",
                        "",
                        x_max,
                        y_max,
                        "",
                        "",
                    ]
                )

            return True, file_annotations

        except Exception as e:
            print(f"Error processing {xml_path}: {str(e)}")
            return False, []

    def create_csv(self, output_path: str = "annotations.csv"):
        """Create the final CSV file"""
        if not self.annotations:
            print("No valid annotations found!")
            return

        df = pd.DataFrame(
            self.annotations,
            columns=[
                "image_file_name",
                "label",
                "X_MIN",
                "Y_MIN",
                "",
                "",
                "X_MAX",
                "Y_MAX",
                "",
                "",
            ],
        )
        df.to_csv(output_path, index=False, header=False)

    def print_summary(self):
        """Print detailed processing summary with annotation limit info"""
        print("\nProcessing Summary:")
        print(f"Annotation limit: {self.annotation_limit}")
        print(f"Total annotations collected: {self.annotation_count}")
        print(f"Processed images: {len(list(self.processed_dir.glob('*.jpg')))}")

        # Count files in each unwanted directory
        print("\nUnwanted files by reason:")
        total_unwanted = 0
        for reason in UnwantedReason:
            count = len(list(self.unwanted_dirs[reason].glob("*")))
            total_unwanted += count
            print(f"{reason.value}: {count} files")

        # Print progress towards limit
        print(
            f"\nAnnotation Progress: {self.annotation_count}/{self.annotation_limit} "
            f"({(self.annotation_count/self.annotation_limit)*100:.1f}%)"
        )


# |%%--%%| <L6xsoqj7eE|FrTxzlXxmO>
r"""°°°
By building such a comprehensive pipeline, i was able to detect that almost all of my image annotation had xmax or ymax exceeding the height and width. This is most likely the resizing process by roboflow. 

As such, coordinates that are 1 pixel above width and height will be corrected.
°°°"""
# |%%--%%| <FrTxzlXxmO|QzlnqCDo15>

processor = VOCProcessor("./people_ladder_copy/train", annotation_limit=300)
processor.process_files()
processor.create_csv()
processor.print_summary()

# |%%--%%| <QzlnqCDo15|ES4Q9UbxJU>

!head -5 annotations.csv

# |%%--%%| <ES4Q9UbxJU|IVETESCJda>

import csv 
class CSVValidator:
    def __init__(self, csv_path: str):
        self.csv_path = csv_path
        self.errors = []
        self.warnings = []

    def validate_row_format(self, row: list, line_num: int) -> bool:
        """Validate single row format"""
        try:
            # Check number of columns (should be 10)
            if len(row) != 10:
                self.errors.append(f"Line {line_num}: Invalid number of columns ({len(row)}), expected 10")
                return False

            # Check if image path starts with gs://
            if not row[0].startswith('gs://i220342h-3386-aip/train/'):
                self.errors.append(f"Line {line_num}: Invalid image path format: {row[0]}")
                return False

            # Check label
            if not row[1] in ['Person', 'Ladder']:
                self.errors.append(f"Line {line_num}: Invalid label: {row[1]}")
                return False

            # Validate coordinate format and values
            coords = [row[2], row[3], row[6], row[7]]  # xmin, ymin, xmax, ymax
            for i, coord in enumerate(coords):
                try:
                    value = float(coord)
                    if value < 0 or value > 1:
                        self.errors.append(f"Line {line_num}: Coordinate out of range [0,1]: {value}")
                        return False
                except ValueError:
                    self.errors.append(f"Line {line_num}: Invalid coordinate format: {coord}")
                    return False

            # Check if xmin < xmax and ymin < ymax
            xmin, ymin, xmax, ymax = map(float, coords)
            if xmin >= xmax:
                self.errors.append(f"Line {line_num}: xmin ({xmin}) >= xmax ({xmax})")
                return False
            if ymin >= ymax:
                self.errors.append(f"Line {line_num}: ymin ({ymin}) >= ymax ({ymax})")
                return False

            # Check empty columns
            if any(row[i] != '' for i in [4, 5, 8, 9]):
                self.errors.append(f"Line {line_num}: Non-empty value in required empty column")
                return False

            return True

        except Exception as e:
            self.errors.append(f"Line {line_num}: Unexpected error: {str(e)}")
            return False

    def validate_csv(self) -> bool:
        """Validate entire CSV file"""
        print(f"Validating CSV file: {self.csv_path}")
        valid = True
        row_count = 0
        
        try:
            with open(self.csv_path, 'r') as f:
                reader = csv.reader(f)
                for i, row in enumerate(reader, 1):
                    row_count += 1
                    if not self.validate_row_format(row, i):
                        valid = False

            # Additional dataset-level checks
            if row_count == 0:
                self.errors.append("Empty CSV file")
                valid = False
            elif row_count > 300:
                self.errors.append(f"Too many annotations: {row_count} (limit is 300)")
                valid = False

            # Check label balance
            self.check_label_balance()

            return valid

        except Exception as e:
            self.errors.append(f"Failed to read CSV file: {str(e)}")
            return False

    def check_label_balance(self):
        """Check balance between Person and Ladder annotations"""
        label_counts = {'Person': 0, 'Ladder': 0}
        
        with open(self.csv_path, 'r') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) > 1:  # Ensure row has enough columns
                    label_counts[row[1]] += 1

        total = sum(label_counts.values())
        for label, count in label_counts.items():
            ratio = count / total if total > 0 else 0
            if ratio < 0.3:  # Less than 30% of any class
                self.warnings.append(f"Imbalanced dataset: {label} only appears in {ratio:.1%} of annotations")

    def print_report(self):
        """Print validation report"""
        print("\nCSV Validation Report")
        print("=" * 50)
        
        if self.errors:
            print("\nErrors:")
            for error in self.errors:
                print(f"❌ {error}")
        
        if self.warnings:
            print("\nWarnings:")
            for warning in self.warnings:
                print(f"⚠️ {warning}")
        
        if not self.errors and not self.warnings:
            print("✅ All validations passed!")

# |%%--%%| <IVETESCJda|AMc7DFvMyE>

    # Validate the CSV
    validator = CSVValidator("annotations.csv")
    is_valid = validator.validate_csv()
    validator.print_report()
    
    if not is_valid:
        print("\n❌ CSV validation failed! Please fix errors before submitting.")
    else:
        print("\n✅ CSV is valid and ready for submission!")

# |%%--%%| <AMc7DFvMyE|dYS51GSjCu>
r"""°°°
## 2.2 Google Cloud Storage

°°°"""
# |%%--%%| <dYS51GSjCu|Gm5YSCtlkp>
r"""°°°
Ensure the following are installed in your local environment:
- The Google Cloud SDK (refer to Practical 2_2)
- Execute the following command to set up your Conda environment before proceeding
    - <code>conda install -c conda-forge google-cloud-aiplatform google-cloud-storage</code>
    
Refer to the assignment brief on where you can obtain your 
1. project_id (contains your admin number, ending with **small** cap letter)
2. service_account
3. service_account_key.json
°°°"""
# |%%--%%| <Gm5YSCtlkp|ReCYLb1eoe>

PROJECT_ID = "i220342h"

# |%%--%%| <ReCYLb1eoe|QTKEQMjXAT>

# do not change
REGION = "us-central1"

# |%%--%%| <QTKEQMjXAT|hieyz9UhW4>

%env GOOGLE_APPLICATION_CREDENTIALS=key_i220342h.json

# |%%--%%| <hieyz9UhW4|ZsWymeD7v2>

!cat $GOOGLE_APPLICATION_CREDENTIALS

# |%%--%%| <ZsWymeD7v2|xXWomLmNqQ>
r"""°°°
### Cloud Storage bucket

When you initialize the Vertex AI SDK for Python, you specify a Cloud Storage staging bucket. The staging bucket is where all the data associated with your dataset and model resources are retained across sessions.

The name of your Cloud Storage bucket is set below. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.
°°°"""
# |%%--%%| <xXWomLmNqQ|YbQIepGESR>

# do not change
BUCKET_NAME = PROJECT_ID + "-3386-aip"
BUCKET_URI = f"gs://{BUCKET_NAME}"

# |%%--%%| <YbQIepGESR|elCgYzVVLJ>

print(BUCKET_URI)

# |%%--%%| <elCgYzVVLJ|9V8sWFcQQd>

from google.cloud import storage
storage_client = storage.Client()

# |%%--%%| <9V8sWFcQQd|6cbgVH1T6r>
r"""°°°
Set up ADC to use your service account. Refer to Practical 7 for details on Google Cloud Storage setup and how to upload your images and annotation file.
°°°"""
# |%%--%%| <6cbgVH1T6r|HVPqGGvZK0>

my_bucket = storage_client.create_bucket(BUCKET_NAME)

# |%%--%%| <HVPqGGvZK0|ihMZWKuJpy>

buckets = storage_client.list_buckets()
for bucket in buckets:
    print(bucket.name)

# |%%--%%| <ihMZWKuJpy|bCG56HPE3D>

def upload_directory_with_transfer_manager(bucket, source_directory, workers=8):
    """Upload every file in a directory, including all files in subdirectories.

    Each blob name is derived from the filename, not including the `directory`
    parameter itself. For complete control of the blob name for each file (and
    other aspects of individual blob metadata), use
    transfer_manager.upload_many() instead.
    """

    # The ID of your GCS bucket
    # bucket_name = "your-bucket-name"

    # The directory on your computer to upload. Files in the directory and its
    # subdirectories will be uploaded. An empty string means "the current
    # working directory".
    # source_directory=""

    # The maximum number of processes to use for the operation. The performance
    # impact of this value depends on the use case, but smaller files usually
    # benefit from a higher number of processes. Each additional process occupies
    # some CPU and memory resources until finished. Threads can be used instead
    # of processes by passing `worker_type=transfer_manager.THREAD`.
    # workers=8

    from pathlib import Path

    from google.cloud.storage import Client, transfer_manager

    # Generate a list of paths (in string form) relative to the `directory`.
    # This can be done in a single list comprehension, but is expanded into
    # multiple lines here for clarity.

    # First, recursively get all files in `directory` as Path objects.
    directory_as_path_obj = Path(source_directory)
    paths = directory_as_path_obj.rglob("*")

    # Filter so the list only includes files, not directories themselves.
    file_paths = [path for path in paths if path.is_file()]

    # These paths are relative to the current working directory. Next, make them
    # relative to `directory`
    relative_paths = [path.relative_to(source_directory) for path in file_paths]

    # Finally, convert them all to strings.
    string_paths = [str(path) for path in relative_paths]

    print("Found {} files.".format(len(string_paths)))
    
    # filenames must in forward slashes to create the corresponding folder inside bucket
    string_paths[:] = [Path(path).as_posix() for path in string_paths]
    
    # Start the upload.
    results = transfer_manager.upload_many_from_filenames(
        bucket, string_paths, source_directory=source_directory, max_workers=workers
    )

    for name, result in zip(string_paths, results):
        # The results list is either `None` or an exception for each filename in
        # the input list, in order.

        if isinstance(result, Exception):
            print("Failed to upload {} due to exception: {}".format(name, result))
        else:
            print("Uploaded {} to {}.".format(name, bucket.name))

# |%%--%%| <bCG56HPE3D|6DUXiE8est>

!ls ./no_name/train

# |%%--%%| <6DUXiE8est|F1seTuey3T>

def verify_image_csv_match(csv_path: str, image_dir: str):
    """
    Verify 1-1 matching between images in directory and CSV entries.
    """
    # Get all jpg files from directory
    image_dir = Path(image_dir)
    directory_images = set(f.name for f in image_dir.glob('*.jpg'))
    
    # Get all image names from CSV
    csv_images = set()
    with open(csv_path, 'r') as f:
        reader = csv.reader(f)
        for row in reader:
            # Extract filename from gs://project/train/filename.jpg
            image_name = Path(row[0]).name
            csv_images.add(image_name)
    
    # Find mismatches
    images_not_in_csv = directory_images - csv_images
    images_not_in_dir = csv_images - directory_images
    
    # Print results
    print("\nImage-CSV Matching Check:")
    print(f"Images in directory: {len(directory_images)}")
    print(f"Images in CSV: {len(csv_images)}")
    
    if images_not_in_csv:
        print("\n❌ Images in directory but missing from CSV:")
        for img in sorted(images_not_in_csv):
            print(f"  - {img}")
    
    if images_not_in_dir:
        print("\n❌ Images in CSV but missing from directory:")
        for img in sorted(images_not_in_dir):
            print(f"  - {img}")
    
    if not images_not_in_csv and not images_not_in_dir:
        print("\n✅ Perfect 1-1 match between directory and CSV!")
        
    return len(images_not_in_csv) == 0 and len(images_not_in_dir) == 0

# Usage
verify_image_csv_match('annotations.csv', "./no_name/train")

# |%%--%%| <F1seTuey3T|jt8sYa3s0b>

print(my_bucket.name)

# |%%--%%| <jt8sYa3s0b|zjxrDVbFsC>
r"""°°°
# Uploading the file
°°°"""
# |%%--%%| <zjxrDVbFsC|VU6mDinSec>

upload_directory_with_transfer_manager(my_bucket, './no_name')

# |%%--%%| <VU6mDinSec|MS7afjc5T4>

# Lists all the blobs in the bucket
blobs = storage_client.list_blobs(BUCKET_NAME)
for blob in blobs:
    print(blob)

# |%%--%%| <MS7afjc5T4|RDTu1x9mfi>
r"""°°°
# Retrieving the image
°°°"""
# |%%--%%| <RDTu1x9mfi|DiDJoaogiz>

import matplotlib.pyplot as plt
from PIL import Image
import io

file_path = 'train/class5_230_jpg.rf.94a7a8fdbf7b71a05840b21456939a38.jpg'
blob = my_bucket.get_blob(file_path)

image = Image.open(io.BytesIO(blob.download_as_bytes()))
plt.imshow(image)
plt.axis("off")

# |%%--%%| <DiDJoaogiz|7qCm108ros>

!ls

# |%%--%%| <7qCm108ros|nvJPlbgQxm>

blob = bucket.blob('train/annotations.csv')
blob.upload_from_filename('annotations.csv')

# |%%--%%| <nvJPlbgQxm|amA2sMWRZS>

blob = bucket.blob('train/annotations.csv')
print(f"File exists: {blob.exists()}")

# |%%--%%| <amA2sMWRZS|i1TUZtdNSq>
r"""°°°
# Bucket size is 5.32MB
°°°"""
# |%%--%%| <i1TUZtdNSq|07pl9lWq8B>

def get_bucket_size(bucket):
    total_size = 0
    for blob in bucket.list_blobs():
        total_size += blob.size
    # Convert to MB or GB for readability
    size_mb = total_size / (1024 * 1024)  # for MB
    size_gb = size_mb / 1024  # for GB
    print(f"Total bucket size: {size_mb:.2f} MB ({size_gb:.2f} GB)")
    return total_size

get_bucket_size(bucket)

# |%%--%%| <07pl9lWq8B|62ZXGPwvXW>
r"""°°°
# Let's continue to AutoML.ipynb
°°°"""
