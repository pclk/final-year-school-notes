{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Web Scraping\n",
    "This cell contains the main web scraping functionality for collecting job data from Glassdoor.\n",
    "Key components:\n",
    "- Selenium WebDriver setup for browser automation\n",
    "- Functions to extract job details like title, description, salary\n",
    "- Handling of country-specific URLs and search terms\n",
    "- Error handling and logging\n",
    "- Metadata management for tracking scraped jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "from random import uniform\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from anthropic import Anthropic\n",
    "import tiktoken\n",
    "import json\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    \"\"\"Configure and return the Chrome WebDriver with appropriate options.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\n",
    "        \"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "def extract_job_details(soup, driver, job_card):\n",
    "    try:\n",
    "        job_data = {\n",
    "            \"country\": \"\",\n",
    "            \"job_description\": \"\",\n",
    "            \"location\": \"\",\n",
    "            \"salary\": \"\",\n",
    "            \"job_title\": \"\",\n",
    "            \"job_link\": \"\",\n",
    "        }\n",
    "\n",
    "        # Get the job link and store it\n",
    "        job_link = job_card.find(\"a\", class_=\"JobCard_trackingLink__HMyun\")\n",
    "        if job_link and job_link.get(\"href\"):\n",
    "            href = job_link.get(\"href\")\n",
    "            if href.startswith(\"/\"):\n",
    "                base_url = \"https://www.glassdoor.com\"\n",
    "                if \"glassdoor.sg\" in driver.current_url:\n",
    "                    base_url = \"https://www.glassdoor.sg\"\n",
    "                elif \"glassdoor.co.in\" in driver.current_url:\n",
    "                    base_url = \"https://www.glassdoor.co.in\"\n",
    "                job_data[\"job_link\"] = base_url + href\n",
    "            else:\n",
    "                job_data[\"job_link\"] = href\n",
    "\n",
    "        # Extract salary by iterating through possible salary elements\n",
    "        try:\n",
    "            # Find all salary elements in the job cards\n",
    "            salary_elements = driver.find_elements(\n",
    "                By.CSS_SELECTOR, \"[data-test='detailSalary']\"\n",
    "            )\n",
    "\n",
    "            # Get the current job's href to match with the correct salary\n",
    "            current_job_href = job_link.get(\"href\") if job_link else None\n",
    "\n",
    "            if current_job_href:\n",
    "                # Find the matching salary element for this job card\n",
    "                salary_found = False\n",
    "                for salary_element in salary_elements:\n",
    "                    # Get the parent job card element\n",
    "                    parent_card = salary_element.find_element(\n",
    "                        By.XPATH, (\"./ancestor::div[contains(@class, 'jobCard')]\")\n",
    "                    )\n",
    "                    card_link = parent_card.find_element(\n",
    "                        By.CSS_SELECTOR, \"a[data-test='job-link']\"\n",
    "                    )\n",
    "\n",
    "                    # Check if this is the salary for our current job\n",
    "                    if card_link.get_attribute(\"href\").endswith(current_job_href):\n",
    "                        salary_text = salary_element.text.strip()\n",
    "                        if salary_text and salary_text != \"Salary not available\":\n",
    "                            job_data[\"salary\"] = salary_text\n",
    "                            salary_found = True\n",
    "                            print(\n",
    "                                f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Found matching salary: {job_data['salary']}\"\n",
    "                            )\n",
    "                            break\n",
    "\n",
    "                if not salary_found:\n",
    "                    print(\n",
    "                        f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] No salary found, skipping job\"\n",
    "                    )\n",
    "                    return None\n",
    "            else:\n",
    "                print(\n",
    "                    f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] No job link found, skipping job\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting salary: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # Find and click the job title link\n",
    "        try:\n",
    "            # Check if this job's details are already visible\n",
    "            current_url = driver.current_url\n",
    "            job_href = job_link.get(\"href\")\n",
    "\n",
    "            # Only skip the click if this specific job is already showing\n",
    "            if job_href in current_url:\n",
    "                print(\"This job's details already visible, skipping click\")\n",
    "            else:\n",
    "                job_title_link = WebDriverWait(driver, 1).until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (\n",
    "                            By.CSS_SELECTOR,\n",
    "                            f\"a[data-test='job-link'][href='{job_href}']\",\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Scroll the element into view\n",
    "                driver.execute_script(\n",
    "                    \"arguments[0].scrollIntoView(true);\", job_title_link\n",
    "                )\n",
    "                time.sleep(uniform(0.05, 0.1))  # Minimal pause after scrolling\n",
    "\n",
    "                # Click using JavaScript\n",
    "                driver.execute_script(\"arguments[0].click();\", job_title_link)\n",
    "\n",
    "                # No need for extra wait here since we'll wait for description element in get_full_description\n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking job details: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # Now extract the job details from the expanded view\n",
    "        job_data[\"job_description\"] = (\n",
    "            get_full_description(driver) or \"Description not available\"\n",
    "        )\n",
    "\n",
    "        # Extract location using XPath\n",
    "        try:\n",
    "            location_element = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (\n",
    "                        By.XPATH,\n",
    "                        \"//*[@id='app-navigation']/div[4]/div[2]/div[2]/div/div[1]/header/div[1]/div\",\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            job_data[\"location\"] = location_element.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting location: {str(e)}\")\n",
    "            job_data[\"location\"] = \"Location not available\"\n",
    "\n",
    "        # Extract job title by iterating through possible title elements\n",
    "        try:\n",
    "            # Find all title elements in the job cards\n",
    "            title_elements = driver.find_elements(\n",
    "                By.XPATH,\n",
    "                \"//*[@id='left-column']/div[2]/ul/li/div/div/div[1]/div[1]/a[1]\",\n",
    "            )\n",
    "\n",
    "            # Get the current job's href to match with the correct title\n",
    "            current_job_href = job_link.get(\"href\") if job_link else None\n",
    "\n",
    "            if current_job_href:\n",
    "                # Find the matching title element for this job card\n",
    "                for title_element in title_elements:\n",
    "                    # Get the parent job card element\n",
    "                    parent_card = title_element.find_element(\n",
    "                        By.XPATH, \"./ancestor::div[contains(@class, 'jobCard')]\"\n",
    "                    )\n",
    "                    card_link = parent_card.find_element(\n",
    "                        By.CSS_SELECTOR, \"a[data-test='job-link']\"\n",
    "                    )\n",
    "\n",
    "                    # Check if this is the title for our current job\n",
    "                    if card_link.get_attribute(\"href\").endswith(current_job_href):\n",
    "                        job_data[\"job_title\"] = title_element.text.strip()\n",
    "                        print(\n",
    "                            f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Found matching job title: {job_data['job_title']}\"\n",
    "                        )\n",
    "                        break\n",
    "                else:\n",
    "                    job_data[\"job_title\"] = \"Title not available\"\n",
    "            else:\n",
    "                job_data[\"job_title\"] = \"Title not available\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting job title: {str(e)}\")\n",
    "            job_data[\"job_title\"] = \"Title not available\"\n",
    "\n",
    "        # Store the job link for reference\n",
    "        job_link = job_card.find(\"a\", class_=\"JobCard_trackingLink__HMyun\")\n",
    "        if job_link and job_link.get(\"href\"):\n",
    "            href = job_link.get(\"href\")\n",
    "            if href.startswith(\"/\"):\n",
    "                base_url = \"https://www.glassdoor.com\"\n",
    "                if \"glassdoor.sg\" in driver.current_url:\n",
    "                    base_url = \"https://www.glassdoor.sg\"\n",
    "                elif \"glassdoor.co.in\" in driver.current_url:\n",
    "                    base_url = \"https://www.glassdoor.co.in\"\n",
    "                job_data[\"job_link\"] = base_url + href\n",
    "            else:\n",
    "                job_data[\"job_link\"] = href\n",
    "\n",
    "        return job_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting job details: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "def get_full_description(driver):\n",
    "    \"\"\"Get the full job description from the expanded job card view.\"\"\"\n",
    "    try:\n",
    "        # First ensure no modal is present\n",
    "        def close_any_modal():\n",
    "            try:\n",
    "                close_button = WebDriverWait(driver, 0.5).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, \"CloseButton\"))\n",
    "                )\n",
    "                if close_button.is_displayed():\n",
    "                    driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "                    print(\n",
    "                        f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Modal detected and closed\"\n",
    "                    )\n",
    "                    time.sleep(uniform(0.05, 0.1))\n",
    "                    return True\n",
    "                return False\n",
    "            except:\n",
    "                return False\n",
    "\n",
    "        # Try to close modal if present\n",
    "        close_any_modal()\n",
    "\n",
    "        # Use the most reliable Show More button selector\n",
    "        try:\n",
    "            show_more_button = WebDriverWait(driver, 0.5).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, \"button[class*='JobDetails_showMore___']\")\n",
    "                )\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "            print(\n",
    "                f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Clicked 'Show More' button\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\"'Show More' button not found\")\n",
    "\n",
    "        # Try to get the description using the specific XPath\n",
    "        try:\n",
    "            description_element = WebDriverWait(driver, 2).until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (\n",
    "                        By.XPATH,\n",
    "                        \"//*[@id='app-navigation']/div[4]/div[2]/div[2]/div/div[1]/section/div[2]/div[1]\",\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            description = description_element.text.strip()\n",
    "            if description:\n",
    "                print(\n",
    "                    f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Found job description\"\n",
    "                )\n",
    "                return description\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting description using XPath: {str(e)}\")\n",
    "\n",
    "        return \"Description not available\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting full description: {str(e)}\")\n",
    "        return \"Description not available\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "def extract_job_id(url):\n",
    "    \"\"\"Extract jobListingId from URL\"\"\"\n",
    "    try:\n",
    "        if \"?\" in url:\n",
    "            params = dict(param.split(\"=\") for param in url.split(\"?\")[1].split(\"&\"))\n",
    "            return params.get(\"jobListingId\")\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_metadata():\n",
    "    \"\"\"Load metadata of previously scraped jobs\"\"\"\n",
    "    if os.path.exists(\"scraping_metadata.json\"):\n",
    "        with open(\"scraping_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "            # Convert the URLs to job IDs\n",
    "            job_ids = {\n",
    "                extract_job_id(url)\n",
    "                for url in data[\"scraped_jobs\"]\n",
    "                if extract_job_id(url)\n",
    "            }\n",
    "            data[\"scraped_jobs\"] = job_ids\n",
    "            return data\n",
    "    return {\"scraped_jobs\": set(), \"last_scrape_date\": None, \"total_jobs_scraped\": 0}\n",
    "\n",
    "\n",
    "def save_metadata(metadata):\n",
    "    \"\"\"Save metadata of scraped jobs\"\"\"\n",
    "    # Convert set to list for JSON serialization\n",
    "    metadata[\"scraped_jobs\"] = list(metadata[\"scraped_jobs\"])\n",
    "    with open(\"scraping_metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "def scrape_glassdoor_jobs(query, country, jobs_per_country=50):\n",
    "    \"\"\"Main function to scrape Glassdoor jobs.\n",
    "\n",
    "    Args:\n",
    "        query (str): Job search query\n",
    "        country (str): Country code to search in\n",
    "        jobs_per_country (int): Number of jobs to scrape per country\n",
    "    \"\"\"\n",
    "    if country not in glassdoor_links_map:\n",
    "        raise ValueError(\n",
    "            f\"Country '{country}' not supported. Available countries: {', '.join(glassdoor_links_map.keys())}\"\n",
    "        )\n",
    "\n",
    "    # Load metadata of previously scraped jobs\n",
    "    metadata = load_metadata()\n",
    "    scraped_jobs = set(metadata[\"scraped_jobs\"])  # Convert back to set\n",
    "    print(f\"Found {len(scraped_jobs)} previously scraped jobs\")\n",
    "    print(\"First few scraped job links:\", list(scraped_jobs)[:3])  # Debug print\n",
    "\n",
    "    driver = setup_driver()\n",
    "    jobs = []\n",
    "\n",
    "    # Define CSV headers\n",
    "    fieldnames = [\n",
    "        \"query\",\n",
    "        \"country\",\n",
    "        \"job_description\",\n",
    "        \"location\",\n",
    "        \"salary\",\n",
    "        \"job_title\",\n",
    "        \"job_link\",\n",
    "    ]\n",
    "\n",
    "    # Create or open CSV file\n",
    "    file_exists = os.path.isfile(\"glassdoor.csv\")\n",
    "    with open(\"glassdoor.csv\", mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "    try:\n",
    "        base_url = glassdoor_links_map[country]\n",
    "        query_formatted = query.replace(\" \", \"-\")\n",
    "        # Calculate the correct query length based on the actual position in the URL\n",
    "        query_len = 14\n",
    "        if country == \"US\":\n",
    "            query_len = len(query_formatted) + 14\n",
    "        elif country == \"SG\":\n",
    "            query_len = len(query_formatted) + 10\n",
    "        elif country == \"IN\":\n",
    "            query_len = len(query_formatted) + 6\n",
    "\n",
    "        url = base_url.format(query=query_formatted, query_len=query_len)\n",
    "\n",
    "        current_job_count = 0\n",
    "        page = 1\n",
    "\n",
    "        while current_job_count < jobs_per_country:\n",
    "            if page > 1:\n",
    "                url = f\"{url}?p={page}\"\n",
    "            print(\n",
    "                f\"\\nProcessing page {page} for {country}. Current jobs: {current_job_count}/{jobs_per_country}\"\n",
    "            )\n",
    "\n",
    "            driver.get(url)\n",
    "            print(\n",
    "                f\"\\n[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Current URL: {url}\"\n",
    "            )\n",
    "            print(f\"Attempting to load job cards on page {page + 1}...\")\n",
    "\n",
    "            try:\n",
    "                # Single wait for job cards to load using a specific selector\n",
    "                WebDriverWait(driver, 1).until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (By.CSS_SELECTOR, \"[data-test='job-link']\")\n",
    "                    )\n",
    "                )\n",
    "                print(\n",
    "                    f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Job cards loaded successfully\"\n",
    "                )\n",
    "            except TimeoutException:\n",
    "                print(\"ERROR: Timeout waiting for job cards to load\")\n",
    "                print(\"Current page source:\")\n",
    "                print(driver.page_source[:500])  # Print first 500 chars of page source\n",
    "                raise\n",
    "\n",
    "            # Parse the page\n",
    "            print(\"Parsing page with BeautifulSoup...\")\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            job_cards = soup.find_all(\"div\", class_=\"jobCard\")\n",
    "            print(\n",
    "                f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Found {len(job_cards)} job cards on the page\"\n",
    "            )\n",
    "\n",
    "            for job_card in job_cards:\n",
    "                # Get job link before full extraction to check if already scraped\n",
    "                job_link = job_card.find(\"a\", class_=\"JobCard_trackingLink__HMyun\")\n",
    "                if job_link and job_link.get(\"href\"):\n",
    "                    href = job_link.get(\"href\")\n",
    "\n",
    "                    if href.startswith(\"/\"):\n",
    "                        base_url = \"https://www.glassdoor.com\"\n",
    "                        if \"glassdoor.sg\" in driver.current_url:\n",
    "                            base_url = \"https://www.glassdoor.sg\"\n",
    "                        elif \"glassdoor.co.in\" in driver.current_url:\n",
    "                            base_url = \"https://www.glassdoor.co.in\"\n",
    "                        full_job_link = base_url + href\n",
    "                    else:\n",
    "                        full_job_link = href\n",
    "\n",
    "                    # Extract jobListingId from the current job link\n",
    "                    current_job_id = extract_job_id(full_job_link)\n",
    "                    if current_job_id and current_job_id in scraped_jobs:\n",
    "                        # Convert set to list for indexing\n",
    "                        scraped_list = list(scraped_jobs)\n",
    "                        index = scraped_list.index(current_job_id)\n",
    "                        print(\n",
    "                            f\"Skipping already scraped job (index {index}): jobListingId={current_job_id}\"\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                job = extract_job_details(soup, driver, job_card)\n",
    "                if job:\n",
    "                    # Add country and search term information\n",
    "                    job[\"country\"] = country\n",
    "                    job[\"query\"] = query\n",
    "\n",
    "                    # Job description is already fetched in extract_job_details\n",
    "                    if not job.get(\"job_description\"):\n",
    "                        job[\"job_description\"] = \"Description not available\"\n",
    "\n",
    "                    # Add job ID to scraped jobs set\n",
    "                    job_id = extract_job_id(job[\"job_link\"])\n",
    "                    if job_id:\n",
    "                        scraped_jobs.add(job_id)\n",
    "\n",
    "                    # Save to CSV\n",
    "                    with open(\n",
    "                        \"glassdoor.csv\", mode=\"a\", newline=\"\", encoding=\"utf-8\"\n",
    "                    ) as f:\n",
    "                        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                        writer.writerow(job)\n",
    "\n",
    "                    jobs.append(job)\n",
    "                    current_job_count += 1\n",
    "\n",
    "                    # Check if we've reached the target number of jobs\n",
    "                    if current_job_count >= jobs_per_country:\n",
    "                        print(\n",
    "                            f\"Reached target of {jobs_per_country} jobs for {country}\"\n",
    "                        )\n",
    "                        break\n",
    "\n",
    "            # Break the loop if we've reached the target\n",
    "            if current_job_count >= jobs_per_country:\n",
    "                break\n",
    "\n",
    "            # After processing all job cards, try to click \"Show More Jobs\" button\n",
    "            try:\n",
    "                # Quick check for modal\n",
    "                try:\n",
    "                    close_button = driver.find_element(By.CLASS_NAME, \"CloseButton\")\n",
    "                    if close_button.is_displayed():\n",
    "                        driver.execute_script(\"arguments[0].click();\", close_button)\n",
    "                except:\n",
    "                    pass  # No modal present, continue\n",
    "\n",
    "                show_more_jobs = WebDriverWait(driver, 3).until(\n",
    "                    EC.element_to_be_clickable(\n",
    "                        (By.XPATH, '//*[@id=\"left-column\"]/div[2]/div/div/button')\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Scroll the button into view and ensure it's clickable\n",
    "                driver.execute_script(\n",
    "                    \"arguments[0].scrollIntoView({block: 'center'});\", show_more_jobs\n",
    "                )\n",
    "                WebDriverWait(driver, 2).until(\n",
    "                    EC.element_to_be_clickable(\n",
    "                        (By.XPATH, '//*[@id=\"left-column\"]/div[2]/div/div/button')\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Click using JavaScript\n",
    "                driver.execute_script(\"arguments[0].click();\", show_more_jobs)\n",
    "                print(\n",
    "                    f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Clicked 'Show More Jobs' button\"\n",
    "                )\n",
    "\n",
    "                # Wait for new job cards to load (wait for count to increase)\n",
    "                old_count = len(driver.find_elements(By.CLASS_NAME, \"jobCard\"))\n",
    "                try:\n",
    "                    WebDriverWait(driver, 0.5).until(\n",
    "                        lambda x: len(x.find_elements(By.CLASS_NAME, \"jobCard\"))\n",
    "                        > old_count\n",
    "                    )\n",
    "                except TimeoutException:\n",
    "                    print(\"Timeout waiting for new cards, continuing anyway...\")\n",
    "\n",
    "                # Update the soup and job cards with new content\n",
    "                soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                job_cards = soup.find_all(\"div\", class_=\"jobCard\")\n",
    "                print(\n",
    "                    f\"[{datetime.now().strftime('%H:%M:%S.%f')[:-3]}] Found {len(job_cards)} job cards after loading more\"\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"No more jobs to load or error clicking 'Show More Jobs' button: {str(e)}\"\n",
    "                )\n",
    "                break  # Exit the loop if we can't load more jobs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during scraping: {str(e)}\")\n",
    "    finally:\n",
    "        # Update metadata before quitting\n",
    "        metadata[\"scraped_jobs\"] = list(scraped_jobs)\n",
    "        metadata[\"last_scrape_date\"] = datetime.now().isoformat()\n",
    "        metadata[\"total_jobs_scraped\"] = len(scraped_jobs)\n",
    "        save_metadata(metadata)\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "COMMON_SEARCH_TERMS = [\n",
    "    \"software engineer\",\n",
    "    \"data scientist\",\n",
    "    \"product manager\",\n",
    "    \"data analyst\",\n",
    "    \"software developer\",\n",
    "    \"project manager\",\n",
    "    \"business analyst\",\n",
    "    \"full stack developer\",\n",
    "    \"data engineer\",\n",
    "    \"frontend developer\",\n",
    "    \"backend developer\",\n",
    "    \"devops engineer\",\n",
    "    \"machine learning engineer\",\n",
    "    \"systems engineer\",\n",
    "    \"qa engineer\",\n",
    "    \"cloud engineer\",\n",
    "    \"java developer\",\n",
    "    \"python developer\",\n",
    "    \"web developer\",\n",
    "    \"solutions architect\",\n",
    "    \"it manager\",\n",
    "    \"network engineer\",\n",
    "    \"security engineer\",\n",
    "    \"database administrator\",\n",
    "    \"ui ux designer\",\n",
    "    \"scrum master\",\n",
    "    \"android developer\",\n",
    "    \"ios developer\",\n",
    "    \"site reliability engineer\",\n",
    "    \"technical lead\",\n",
    "    \"automation engineer\",\n",
    "    \"research scientist\",\n",
    "    \"ai engineer\",\n",
    "    \"blockchain developer\",\n",
    "    \"cloud architect\",\n",
    "    \"cybersecurity analyst\",\n",
    "    \"data architect\",\n",
    "    \"embedded engineer\",\n",
    "    \"full stack engineer\",\n",
    "    \"infrastructure engineer\",\n",
    "    \"javascript developer\",\n",
    "    \"mobile developer\",\n",
    "    \"network administrator\",\n",
    "    \"product owner\",\n",
    "    \"quality assurance\",\n",
    "    \"ruby developer\",\n",
    "    \"security analyst\",\n",
    "    \"software architect\",\n",
    "    \"systems administrator\",\n",
    "    \"technical architect\",\n",
    "    \"unity developer\",\n",
    "    \"accountant\",\n",
    "    \"financial analyst\",\n",
    "    \"auditor\",\n",
    "    \"financial manager\",\n",
    "    \"actuary\",\n",
    "    \"marketing manager\",\n",
    "    \"marketing specialist\",\n",
    "    \"sales manager\",\n",
    "    \"sales representative\",\n",
    "    \"digital marketing specialist\",\n",
    "    \"graphic designer\",\n",
    "    \"copywriter\",\n",
    "    \"content writer\",\n",
    "    \"public relations specialist\",\n",
    "    \"social media manager\",\n",
    "    \"human resources manager\",\n",
    "    \"hr specialist\",\n",
    "    \"recruiter\",\n",
    "    \"training manager\",\n",
    "    \"payroll specialist\",\n",
    "    \"teacher\",\n",
    "    \"professor\",\n",
    "    \"instructional designer\",\n",
    "    \"principal\",\n",
    "    \"school counselor\",\n",
    "    \"nurse\",\n",
    "    \"physician\",\n",
    "    \"pharmacist\",\n",
    "    \"medical assistant\",\n",
    "    \"physical therapist\",\n",
    "    \"registered nurse\",\n",
    "    \"medical doctor\",\n",
    "    \"therapist\",\n",
    "    \"project coordinator\",\n",
    "    \"operations manager\",\n",
    "    \"supply chain manager\",\n",
    "    \"logistics coordinator\",\n",
    "    \"purchasing manager\",\n",
    "    \"restaurant manager\",\n",
    "    \"chef\",\n",
    "    \"bartender\",\n",
    "    \"waiter/waitress\",\n",
    "    \"event planner\",\n",
    "    \"hotel manager\",\n",
    "    \"civil engineer\",\n",
    "    \"electrical engineer\",\n",
    "    \"mechanical engineer\",\n",
    "    \"chemical engineer\",\n",
    "    \"environmental engineer\",\n",
    "    \"architect\",\n",
    "    \"urban planner\",\n",
    "    \"construction manager\",\n",
    "    \"biomedical engineer\",\n",
    "    \"manufacturing engineer\",\n",
    "    \"legal assistant\",\n",
    "    \"paralegal\",\n",
    "    \"lawyer\",\n",
    "    \"attorney\",\n",
    "    \"legal secretary\",\n",
    "    \"data entry clerk\",\n",
    "    \"office manager\",\n",
    "    \"administrative assistant\",\n",
    "    \"customer service representative\",\n",
    "    \"executive assistant\",\n",
    "    \"receptionist\",\n",
    "    \"business development manager\",\n",
    "    \"management consultant\",\n",
    "    \"market research analyst\",\n",
    "    \"statistician\",\n",
    "    \"economist\",\n",
    "    \"ux researcher\",\n",
    "    \"technical writer\",\n",
    "    \"scientific writer\",\n",
    "    \"librarian\",\n",
    "    \"journalist\",\n",
    "    \"editor\",\n",
    "    \"translator\",\n",
    "    \"interpreter\",\n",
    "    \"pharmacovigilance specialist\",\n",
    "    \"clinical research associate\",\n",
    "    \"biostatistician\",\n",
    "    \"regulatory affairs specialist\",\n",
    "    \"lab technician\",\n",
    "    \"research associate\",\n",
    "    \"geneticist\",\n",
    "    \"zoologist\",\n",
    "    \"geologist\",\n",
    "    \"astronomer\",\n",
    "    \"mathematician\",\n",
    "    \"actuarial analyst\",\n",
    "    \"investment banker\",\n",
    "    \"portfolio manager\",\n",
    "    \"loan officer\",\n",
    "    \"risk manager\",\n",
    "    \"compliance officer\",\n",
    "    \"estate agent\",\n",
    "    \"insurance agent\",\n",
    "    \"real estate agent\",\n",
    "    \"social worker\",\n",
    "    \"psychologist\",\n",
    "    \"counselor\",\n",
    "    \"supply chain analyst\",\n",
    "    \"logistics manager\",\n",
    "    \"warehouse manager\",\n",
    "    \"inventory specialist\",\n",
    "    \"procurement specialist\",\n",
    "    \"planner\",\n",
    "    \"demand planner\",\n",
    "    \"merchandiser\",\n",
    "    \"quality control inspector\",\n",
    "    \"production supervisor\",\n",
    "    \"operations analyst\",\n",
    "    \"manufacturing supervisor\",\n",
    "    \"process engineer\",\n",
    "    \"industrial engineer\",\n",
    "    \"maintenance technician\",\n",
    "    \"facilities manager\",\n",
    "    \"construction worker\",\n",
    "    \"electrician\",\n",
    "    \"plumber\",\n",
    "    \"carpenter\",\n",
    "    \"welder\",\n",
    "    \"painter\",\n",
    "    \"hvac technician\",\n",
    "    \"automotive technician\",\n",
    "    \"diesel mechanic\",\n",
    "    \"aircraft mechanic\",\n",
    "    \"pilot\",\n",
    "    \"air traffic controller\",\n",
    "    \"flight attendant\",\n",
    "    \"customer success manager\",\n",
    "    \"sales director\",\n",
    "    \"account manager\",\n",
    "    \"brand manager\",\n",
    "    \"public relations manager\",\n",
    "    \"communications manager\",\n",
    "    \"content strategist\",\n",
    "    \"seo specialist\",\n",
    "    \"social media strategist\",\n",
    "    \"marketing analyst\",\n",
    "    \"advertising manager\",\n",
    "    \"media planner\",\n",
    "    \"event coordinator\",\n",
    "    \"market research manager\",\n",
    "    \"graphic artist\",\n",
    "    \"illustrator\",\n",
    "    \"video editor\",\n",
    "    \"photographer\",\n",
    "    \"game developer\",\n",
    "    \"animator\",\n",
    "    \"audio engineer\",\n",
    "    \"sound designer\",\n",
    "    \"film director\",\n",
    "    \"art director\",\n",
    "    \"fashion designer\",\n",
    "    \"interior designer\",\n",
    "    \"ux designer\",\n",
    "    \"ui designer\",\n",
    "    \"data visualization specialist\",\n",
    "    \"training coordinator\",\n",
    "    \"learning and development specialist\",\n",
    "    \"instructional technologist\",\n",
    "    \"corporate trainer\",\n",
    "    \"hr business partner\",\n",
    "    \"employee relations specialist\",\n",
    "    \"benefits administrator\",\n",
    "    \"compensation analyst\",\n",
    "    \"talent acquisition specialist\",\n",
    "    \"organizational development consultant\",\n",
    "    \"early childhood educator\",\n",
    "    \"special education teacher\",\n",
    "    \"curriculum developer\",\n",
    "    \"school administrator\",\n",
    "    \"academic advisor\",\n",
    "    \"education consultant\",\n",
    "    \"medical coder\",\n",
    "    \"medical biller\",\n",
    "    \"dental hygienist\",\n",
    "    \"dental assistant\",\n",
    "    \"medical technologist\",\n",
    "    \"surgical technician\",\n",
    "    \"radiologic technologist\",\n",
    "    \"pharmacy technician\",\n",
    "    \"healthcare administrator\",\n",
    "    \"clinical research coordinator\",\n",
    "    \"epidemiologist\",\n",
    "    \"dietitian\",\n",
    "    \"nutritionist\",\n",
    "    \"speech therapist\",\n",
    "    \"occupational therapist\",\n",
    "    \"athletic trainer\",\n",
    "    \"massage therapist\",\n",
    "    \"physical therapy assistant\",\n",
    "    \"legal secretary\",\n",
    "    \"court reporter\",\n",
    "    \"law clerk\",\n",
    "    \"litigation paralegal\",\n",
    "    \"contract administrator\",\n",
    "    \"compliance analyst\",\n",
    "    \"office assistant\",\n",
    "    \"clerical worker\",\n",
    "    \"data entry operator\",\n",
    "    \"bookkeeper\",\n",
    "    \"payroll clerk\",\n",
    "    \"administrative coordinator\",\n",
    "    \"project analyst\",\n",
    "    \"project controller\",\n",
    "    \"business development analyst\",\n",
    "    \"contract manager\",\n",
    "    \"consultant\",\n",
    "    \"management analyst\",\n",
    "    \"business intelligence analyst\",\n",
    "    \"research analyst\",\n",
    "    \"policy analyst\",\n",
    "    \"statistician analyst\",\n",
    "    \"actuarial consultant\",\n",
    "    \"investment analyst\",\n",
    "    \"financial consultant\",\n",
    "    \"portfolio analyst\",\n",
    "    \"tax analyst\",\n",
    "    \"credit analyst\",\n",
    "    \"underwriter\",\n",
    "    \"financial advisor\",\n",
    "    \"insurance underwriter\",\n",
    "    \"real estate appraiser\",\n",
    "    \"property manager\",\n",
    "    \"community manager\",\n",
    "    \"event manager\",\n",
    "    \"volunteer coordinator\",\n",
    "    \"case manager\",\n",
    "    \"mental health counselor\",\n",
    "    \"rehabilitation counselor\",\n",
    "    \"substance abuse counselor\",\n",
    "    \"probation officer\",\n",
    "    \"human services specialist\",\n",
    "    \"family support specialist\",\n",
    "    \"social media coordinator\",\n",
    "    \"copy editor\",\n",
    "    \"proofreader\",\n",
    "    \"grant writer\",\n",
    "    \"proposal writer\",\n",
    "    \"technical editor\",\n",
    "    \"content editor\",\n",
    "    \"news anchor\",\n",
    "    \"reporter\",\n",
    "    \"columnist\",\n",
    "    \"broadcaster\",\n",
    "    \"communication specialist\",\n",
    "    \"public affairs specialist\",\n",
    "    \"regulatory affairs manager\",\n",
    "    \"quality assurance specialist\",\n",
    "    \"clinical data manager\",\n",
    "    \"laboratory manager\",\n",
    "    \"research fellow\",\n",
    "    \"biochemist\",\n",
    "    \"microbiologist\",\n",
    "    \"environmental scientist\",\n",
    "    \"botanist\",\n",
    "    \"marine biologist\",\n",
    "    \"veterinarian\",\n",
    "    \"astrophysicist\",\n",
    "    \"geophysicist\",\n",
    "    \"data librarian\",\n",
    "    \"archivist\",\n",
    "    \"museum curator\",\n",
    "    \"academic librarian\",\n",
    "    \"investment consultant\",\n",
    "    \"risk analyst\",\n",
    "    \"fraud investigator\",\n",
    "    \"compliance specialist\",\n",
    "    \"real estate broker\",\n",
    "    \"customer service manager\",\n",
    "    \"customer support specialist\",\n",
    "    \"technical support specialist\",\n",
    "    \"renewable energy engineer\",\n",
    "    \"solar energy specialist\",\n",
    "    \"wind energy technician\",\n",
    "    \"energy auditor\",\n",
    "    \"sustainability manager\",\n",
    "    \"environmental consultant\",\n",
    "    \"waste management specialist\",\n",
    "    \"recycling coordinator\",\n",
    "    \"water treatment operator\",\n",
    "    \"environmental health specialist\",\n",
    "    \"agricultural engineer\",\n",
    "    \"horticulturist\",\n",
    "    \"farm manager\",\n",
    "    \"crop specialist\",\n",
    "    \"animal scientist\",\n",
    "    \"food scientist\",\n",
    "    \"chef de cuisine\",\n",
    "    \"sous chef\",\n",
    "    \"pastry chef\",\n",
    "    \"line cook\",\n",
    "    \"food and beverage manager\",\n",
    "    \"catering manager\",\n",
    "    \"sommelier\",\n",
    "    \"barista\",\n",
    "    \"restaurant host\",\n",
    "    \"hotel concierge\",\n",
    "    \"front desk agent\",\n",
    "    \"housekeeping supervisor\",\n",
    "    \"event marketing manager\",\n",
    "    \"tradeshow coordinator\",\n",
    "    \"conference planner\",\n",
    "    \"wedding planner\",\n",
    "    \"public relations coordinator\",\n",
    "    \"media relations manager\",\n",
    "    \"social media analyst\",\n",
    "    \"influencer marketing manager\",\n",
    "    \"digital marketing manager\",\n",
    "    \"email marketing specialist\",\n",
    "    \"paid search specialist\",\n",
    "    \"affiliate marketing manager\",\n",
    "    \"growth hacker\",\n",
    "    \"market development specialist\",\n",
    "    \"product marketing manager\",\n",
    "    \"brand strategist\",\n",
    "    \"creative director\",\n",
    "    \"digital designer\",\n",
    "    \"motion graphic designer\",\n",
    "    \"presentation designer\",\n",
    "    \"web content strategist\",\n",
    "    \"user interface designer\",\n",
    "    \"user experience architect\",\n",
    "    \"game designer\",\n",
    "    \"game artist\",\n",
    "    \"level designer\",\n",
    "    \"character animator\",\n",
    "    \"motion capture artist\",\n",
    "    \"technical artist\",\n",
    "    \"sound editor\",\n",
    "    \"music composer\",\n",
    "    \"film editor\",\n",
    "    \"film producer\",\n",
    "    \"set designer\",\n",
    "    \"costume designer\",\n",
    "    \"makeup artist\",\n",
    "    \"fashion stylist\",\n",
    "    \"interior architect\",\n",
    "    \"landscape architect\",\n",
    "    \"urban designer\",\n",
    "    \"town planner\",\n",
    "    \"community planner\",\n",
    "    \"transportation planner\",\n",
    "    \"construction estimator\",\n",
    "    \"construction superintendent\",\n",
    "    \"civil engineering technician\",\n",
    "    \"electrical engineering technician\",\n",
    "    \"mechanical engineering technician\",\n",
    "    \"draftsman\",\n",
    "    \"cad designer\",\n",
    "    \"building inspector\",\n",
    "    \"safety officer\",\n",
    "    \"occupational health specialist\",\n",
    "    \"quality engineer\",\n",
    "    \"reliability engineer\",\n",
    "    \"test engineer\",\n",
    "    \"validation engineer\",\n",
    "    \"chemical process technician\",\n",
    "    \"environmental technician\",\n",
    "    \"automation technician\",\n",
    "    \"robotics engineer\",\n",
    "    \"mechatronics engineer\",\n",
    "    \"aerospace engineer\",\n",
    "    \"materials engineer\",\n",
    "    \"bioprocess engineer\",\n",
    "    \"clinical laboratory scientist\",\n",
    "    \"medical imaging specialist\",\n",
    "    \"radiology technician\",\n",
    "    \"cardiovascular technologist\",\n",
    "    \"surgical assistant\",\n",
    "    \"patient care technician\",\n",
    "    \"medical transcriptionist\",\n",
    "    \"medical records specialist\",\n",
    "    \"healthcare consultant\",\n",
    "    \"public health specialist\",\n",
    "    \"health educator\",\n",
    "    \"recreational therapist\",\n",
    "    \"art therapist\",\n",
    "    \"music therapist\",\n",
    "    \"dance therapist\",\n",
    "    \"physical medicine specialist\",\n",
    "    \"medical geneticist\",\n",
    "    \"clinical pharmacist\",\n",
    "    \"research pharmacist\",\n",
    "    \"pharmaceutical sales representative\",\n",
    "    \"drug safety specialist\",\n",
    "    \"clinical data analyst\",\n",
    "    \"biostatistical programmer\",\n",
    "    \"epidemiological researcher\",\n",
    "    \"health policy analyst\",\n",
    "    \"community health worker\",\n",
    "    \"social work supervisor\",\n",
    "    \"case management director\",\n",
    "    \"child welfare specialist\",\n",
    "    \"family therapist\",\n",
    "    \"crisis counselor\",\n",
    "    \"rehabilitation specialist\",\n",
    "    \"veteran affairs counselor\",\n",
    "    \"substance abuse counselor\",\n",
    "    \"probation officer\",\n",
    "    \"parole officer\",\n",
    "    \"victim advocate\",\n",
    "    \"human resources director\",\n",
    "    \"talent management specialist\",\n",
    "    \"recruitment manager\",\n",
    "    \"training and development manager\",\n",
    "    \"hr generalist\",\n",
    "    \"compensation and benefits manager\",\n",
    "    \"payroll manager\",\n",
    "    \"employee relations manager\",\n",
    "    \"organizational development manager\",\n",
    "    \"learning technology specialist\",\n",
    "    \"e-learning designer\",\n",
    "    \"training specialist\",\n",
    "    \"instructional coach\",\n",
    "    \"academic dean\",\n",
    "    \"registrar\",\n",
    "    \"admissions counselor\",\n",
    "    \"student services coordinator\",\n",
    "    \"curriculum specialist\",\n",
    "    \"educational psychologist\",\n",
    "    \"school principal\",\n",
    "    \"school superintendent\",\n",
    "    \"university lecturer\",\n",
    "    \"professor emeritus\",\n",
    "    \"research scientist\",\n",
    "    \"postdoctoral researcher\",\n",
    "    \"laboratory assistant\",\n",
    "    \"laboratory technician\",\n",
    "    \"research associate\",\n",
    "    \"data curator\",\n",
    "    \"biomedical researcher\",\n",
    "    \"genetic counselor\",\n",
    "    \"genomics specialist\",\n",
    "    \"immunologist\",\n",
    "    \"neuroscientist\",\n",
    "    \"pathologist\",\n",
    "    \"pharmacologist\",\n",
    "    \"toxicologist\",\n",
    "    \"microbial geneticist\",\n",
    "    \"marine biologist\",\n",
    "    \"zoological park keeper\",\n",
    "    \"wildlife biologist\",\n",
    "    \"astronomy educator\",\n",
    "    \"geological surveyor\",\n",
    "    \"geospatial analyst\",\n",
    "    \"mathematician\",\n",
    "    \"statistical modeler\",\n",
    "    \"quantitative analyst\",\n",
    "    \"actuarial intern\",\n",
    "    \"investment banker analyst\",\n",
    "    \"financial planner\",\n",
    "    \"credit risk manager\",\n",
    "    \"financial risk analyst\",\n",
    "    \"portfolio manager assistant\",\n",
    "    \"hedge fund analyst\",\n",
    "    \"private equity analyst\",\n",
    "    \"venture capital analyst\",\n",
    "    \"compliance auditor\",\n",
    "    \"fraud examiner\",\n",
    "    \"internal auditor\",\n",
    "    \"tax preparer\",\n",
    "    \"accountant specialist\",\n",
    "    \"corporate controller\",\n",
    "    \"cfo\",\n",
    "    \"real estate portfolio manager\",\n",
    "    \"commercial real estate agent\",\n",
    "    \"lease administrator\",\n",
    "    \"property management assistant\",\n",
    "    \"community outreach coordinator\",\n",
    "    \"volunteer coordinator\",\n",
    "    \"nonprofit program manager\",\n",
    "    \"fundraising manager\",\n",
    "    \"development officer\",\n",
    "    \"public affairs manager\",\n",
    "    \"political analyst\",\n",
    "    \"lobbyist\",\n",
    "    \"policy maker\",\n",
    "    \"urban planner\",\n",
    "    \"technical writer manager\",\n",
    "    \"content strategist director\",\n",
    "    \"chief technology officer\",\n",
    "    \"data security manager\",\n",
    "    \"cybersecurity director\",\n",
    "    \"it project manager\",\n",
    "    \"systems engineer specialist\",\n",
    "    \"network administrator manager\",\n",
    "    \"database administrator director\",\n",
    "    \"software quality engineer\",\n",
    "    \"automation engineer manager\",\n",
    "    \"cloud solutions architect\",\n",
    "    \"ai researcher\",\n",
    "    \"machine learning specialist\",\n",
    "    \"deep learning engineer\",\n",
    "    \"blockchain security engineer\",\n",
    "    \"embedded systems developer\",\n",
    "    \"computer vision engineer\",\n",
    "    \"data governance specialist\",\n",
    "    \"data compliance analyst\",\n",
    "    \"information architect\",\n",
    "    \"knowledge manager\",\n",
    "    \"business transformation manager\",\n",
    "    \"change management specialist\",\n",
    "    \"process improvement specialist\",\n",
    "    \"agile coach\",\n",
    "    \"scrum team member\",\n",
    "    \"kanban manager\",\n",
    "    \"product growth manager\",\n",
    "    \"technical project manager\",\n",
    "    \"telecommunications engineer\",\n",
    "    \"broadcast engineer\",\n",
    "    \"satellite engineer\",\n",
    "    \"optical engineer\",\n",
    "    \"radar engineer\",\n",
    "    \"robotics technician\",\n",
    "    \"automation specialist\",\n",
    "    \"process control engineer\",\n",
    "    \"industrial designer\",\n",
    "    \"packaging engineer\",\n",
    "    \"logistics coordinator\",\n",
    "    \"supply chain director\",\n",
    "    \"warehouse supervisor\",\n",
    "    \"distribution manager\",\n",
    "    \"import/export manager\",\n",
    "    \"procurement manager\",\n",
    "    \"purchasing agent\",\n",
    "    \"inventory control manager\",\n",
    "    \"quality control director\",\n",
    "    \"compliance manager\",\n",
    "    \"safety manager\",\n",
    "    \"facility operations manager\",\n",
    "    \"maintenance manager\",\n",
    "    \"asset manager\",\n",
    "    \"vendor manager\",\n",
    "    \"contract negotiator\",\n",
    "    \"risk mitigation specialist\",\n",
    "    \"claims adjuster\",\n",
    "    \"loss prevention specialist\",\n",
    "    \"customer support director\",\n",
    "    \"customer relations specialist\",\n",
    "    \"technical trainer\",\n",
    "    \"cartographer\",\n",
    "    \"geographer\",\n",
    "    \"demographer\",\n",
    "    \"statistical geographer\",\n",
    "    \"remote sensing specialist\",\n",
    "    \"geographic information systems specialist\",\n",
    "    \"urban geographer\",\n",
    "    \"spatial analyst\",\n",
    "    \"data visualization developer\",\n",
    "    \"database architect\",\n",
    "    \"data modeling specialist\",\n",
    "    \"etl developer\",\n",
    "    \"business intelligence developer\",\n",
    "    \"data warehouse engineer\",\n",
    "    \"master data management specialist\",\n",
    "    \"data quality analyst\",\n",
    "    \"information security architect\",\n",
    "    \"penetration tester\",\n",
    "    \"vulnerability analyst\",\n",
    "    \"security operations center analyst\",\n",
    "    \"incident responder\",\n",
    "    \"cryptographer\",\n",
    "    \"ethical hacker\",\n",
    "    \"forensic analyst\",\n",
    "    \"network security engineer\",\n",
    "    \"cloud security specialist\",\n",
    "    \"biometrics specialist\",\n",
    "    \"quantum computing engineer\",\n",
    "    \"nanotechnology engineer\",\n",
    "    \"materials scientist\",\n",
    "    \"cognitive scientist\",\n",
    "    \"artificial intelligence researcher\",\n",
    "    \"machine vision specialist\",\n",
    "    \"natural language processing engineer\",\n",
    "    \"roboticist\",\n",
    "    \"automation consultant\",\n",
    "    \"systems integrator\",\n",
    "    \"devops consultant\",\n",
    "    \"site reliability manager\",\n",
    "    \"infrastructure architect\",\n",
    "    \"network operations center technician\",\n",
    "    \"telecommunications technician\",\n",
    "    \"voip engineer\",\n",
    "    \"wireless engineer\",\n",
    "    \"fiber optic technician\",\n",
    "    \"antenna engineer\",\n",
    "    \"broadcast technician\",\n",
    "    \"satellite communications engineer\",\n",
    "    \"optical communications engineer\",\n",
    "    \"radar systems engineer\",\n",
    "    \"sonar systems engineer\",\n",
    "    \"avionics technician\",\n",
    "    \"aircraft maintenance planner\",\n",
    "    \"airframe mechanic\",\n",
    "    \"powerplant mechanic\",\n",
    "    \"aerospace manufacturing engineer\",\n",
    "    \"spacecraft engineer\",\n",
    "    \"rocket scientist\",\n",
    "    \"astrobiologist\",\n",
    "    \"planetary scientist\",\n",
    "    \"solar physicist\",\n",
    "    \"cosmologist\",\n",
    "    \"theoretical physicist\",\n",
    "    \"particle physicist\",\n",
    "    \"nuclear engineer\",\n",
    "    \"radiological physicist\",\n",
    "    \"medical physicist\",\n",
    "    \"biophysicist\",\n",
    "    \"biomechanical engineer\",\n",
    "    \"ergonomist\",\n",
    "    \"rehabilitation engineer\",\n",
    "    \"prosthetist\",\n",
    "    \"orthotist\",\n",
    "    \"clinical trials manager\",\n",
    "    \"medical writer\",\n",
    "    \"scientific editor\",\n",
    "    \"scientific illustrator\",\n",
    "    \"medical illustrator\",\n",
    "    \"health informatics specialist\",\n",
    "    \"bioethicist\",\n",
    "    \"regulatory affairs director\",\n",
    "    \"pharmacovigilance manager\",\n",
    "    \"drug development manager\",\n",
    "    \"toxicology manager\",\n",
    "    \"clinical affairs manager\",\n",
    "    \"medical affairs director\",\n",
    "    \"managed care specialist\",\n",
    "    \"healthcare compliance officer\",\n",
    "    \"quality improvement manager\",\n",
    "    \"patient safety officer\",\n",
    "    \"health system administrator\",\n",
    "    \"long term care administrator\",\n",
    "    \"medical librarian\",\n",
    "    \"veterinary technician\",\n",
    "    \"zoological curator\",\n",
    "    \"anthropolgist\",\n",
    "    \"archaeologist\",\n",
    "    \"paleontologist\",\n",
    "    \"epidemologist\",\n",
    "    \"virologist\",\n",
    "    \"immunologist\",\n",
    "    \"toxicologist\",\n",
    "    \"pharmacologist\",\n",
    "    \"neuroscientist\",\n",
    "    \"cognitive scientist\",\n",
    "    \"linguist\",\n",
    "    \"etymologist\",\n",
    "    \"philologist\",\n",
    "    \"sociologist\",\n",
    "    \"political scientist\",\n",
    "    \"international relations specialist\",\n",
    "    \"urban sociologist\",\n",
    "    \"criminologist\",\n",
    "    \"forensic scientist\",\n",
    "    \"ballistics expert\",\n",
    "    \"serologist\",\n",
    "    \"dna analyst\",\n",
    "    \"voice analyst\",\n",
    "    \"handwriting analyst\",\n",
    "    \"document examiner\",\n",
    "    \"intelligence analyst\",\n",
    "    \"counterintelligence analyst\",\n",
    "    \"geospatial intelligence analyst\",\n",
    "    \"signals intelligence analyst\",\n",
    "    \"human intelligence collector\",\n",
    "    \"open source intelligence analyst\",\n",
    "    \"competitive intelligence analyst\",\n",
    "    \"market intelligence analyst\",\n",
    "    \"business intelligence consultant\",\n",
    "    \"data governance manager\",\n",
    "    \"data steward\",\n",
    "    \"data quality engineer\",\n",
    "    \"database developer\",\n",
    "    \"database modeler\",\n",
    "    \"etl architect\",\n",
    "    \"data migration specialist\",\n",
    "    \"cloud database administrator\",\n",
    "    \"nosql database administrator\",\n",
    "    \"big data engineer\",\n",
    "    \"hadoop developer\",\n",
    "    \"spark developer\",\n",
    "    \"kafka engineer\",\n",
    "    \"data streaming engineer\",\n",
    "    \"data lake architect\",\n",
    "    \"machine learning operations engineer\",\n",
    "    \"artificial intelligence ethicist\",\n",
    "    \"computer vision researcher\",\n",
    "    \"natural language understanding engineer\",\n",
    "    \"speech recognition engineer\",\n",
    "    \"robotics software engineer\",\n",
    "    \"autonomous systems engineer\",\n",
    "    \"internet of things engineer\",\n",
    "    \"edge computing engineer\",\n",
    "    \"virtual reality developer\",\n",
    "    \"augmented reality developer\",\n",
    "    \"game programmer\",\n",
    "    \"graphics programmer\",\n",
    "    \"simulation engineer\",\n",
    "    \"mathematical modeler\",\n",
    "    \"statistical programmer\",\n",
    "    \"biostatistician programmer\",\n",
    "    \"econometrician\",\n",
    "    \"financial engineer\",\n",
    "    \"quantitative analyst developer\",\n",
    "    \"algorithm developer\",\n",
    "    \"cryptocurrency developer\",\n",
    "    \"blockchain engineer\",\n",
    "    \"smart contract developer\",\n",
    "    \"decentralized application developer\",\n",
    "    \"full stack javascript developer\",\n",
    "    \"mern stack developer\",\n",
    "    \"mean stack developer\",\n",
    "    \"lamp stack developer\",\n",
    "    \"rails developer\",\n",
    "    \"django developer\",\n",
    "    \"flask developer\",\n",
    "    \"spring boot developer\",\n",
    "    \".net developer\",\n",
    "    \"c++ developer\",\n",
    "    \"c# developer\",\n",
    "    \"golang developer\",\n",
    "    \"rust developer\",\n",
    "    \"scala developer\",\n",
    "    \"kotlin developer\",\n",
    "    \"swift developer\",\n",
    "    \"objective-c developer\",\n",
    "    \"php developer\",\n",
    "    \"perl developer\",\n",
    "    \"ruby on rails developer\",\n",
    "    \"sql developer\",\n",
    "    \"pl/sql developer\",\n",
    "    \"t-sql developer\",\n",
    "    \"database tester\",\n",
    "    \"software test automation engineer\",\n",
    "    \"performance test engineer\",\n",
    "    \"security test engineer\",\n",
    "    \"mobile test engineer\",\n",
    "    \"embedded software engineer\",\n",
    "    \"firmware engineer\",\n",
    "    \"bios engineer\",\n",
    "    \"driver developer\",\n",
    "    \"operating systems engineer\",\n",
    "    \"network security architect\",\n",
    "    \"cloud security engineer\",\n",
    "    \"application security engineer\",\n",
    "    \"information security analyst\",\n",
    "    \"security consultant\",\n",
    "    \"security auditor\",\n",
    "    \"security operations engineer\",\n",
    "    \"devsecops engineer\",\n",
    "    \"cloud architect\",\n",
    "    \"solutions architect\",\n",
    "    \"enterprise architect\",\n",
    "    \"technical consultant\",\n",
    "    \"it consultant\",\n",
    "    \"sap consultant\",\n",
    "    \"salesforce developer\",\n",
    "    \"dynamics 365 consultant\",\n",
    "    \"oracle fusion consultant\",\n",
    "    \"workday consultant\",\n",
    "    \"servicenow developer\",\n",
    "    \"cybersecurity consultant\",\n",
    "    \"risk consultant\",\n",
    "    \"compliance consultant\",\n",
    "    \"management consultant\",\n",
    "    \"strategy consultant\",\n",
    "    \"operations consultant\",\n",
    "    \"human capital consultant\",\n",
    "    \"financial consultant\",\n",
    "    \"tax consultant\",\n",
    "    \"audit consultant\",\n",
    "    \"actuarial consultant\",\n",
    "    \"investment consultant\",\n",
    "    \"real estate consultant\",\n",
    "    \"environmental consultant\",\n",
    "    \"sustainability consultant\",\n",
    "    \"supply chain consultant\",\n",
    "    \"logistics consultant\",\n",
    "    \"healthcare consultant\",\n",
    "    \"education consultant\",\n",
    "    \"nonprofit consultant\",\n",
    "    \"public sector consultant\",\n",
    "    \"marketing consultant\",\n",
    "    \"sales consultant\",\n",
    "    \"hr consultant\",\n",
    "    \"training consultant\",\n",
    "    \"legal consultant\",\n",
    "    \"technical recruiter\",\n",
    "    \"executive recruiter\",\n",
    "    \"headhunter\",\n",
    "    \"talent acquisition manager\",\n",
    "    \"recruiting coordinator\",\n",
    "    \"hr business partner director\",\n",
    "    \"compensation and benefits director\",\n",
    "    \"training and development director\",\n",
    "    \"organizational development director\",\n",
    "    \"employee relations director\",\n",
    "    \"hr director\",\n",
    "    \"chief human resources officer\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [],
   "source": [
    "# Glassdoor country-specific URLs\n",
    "glassdoor_links_map = {\n",
    "    \"US\": \"https://www.glassdoor.com/Job/united-states-{query}-jobs-SRCH_IL.0,13_IN1_KO14,{query_len}.htm\",\n",
    "    \"SG\": \"https://www.glassdoor.sg/Job/singapore-{query}-jobs-SRCH_IL.0,9_IN217_KO10,{query_len}.htm\",\n",
    "    \"IN\": \"https://www.glassdoor.co.in/Job/india-{query}-jobs-SRCH_IL.0,5_IN115_KO6,{query_len}.htm?includeNoSalaryJobs=true\",\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    JOBS_PER_COUNTRY = 30\n",
    "\n",
    "    # Create a log file for the entire scraping session\n",
    "    session_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    with open(\n",
    "        f\"scraping_session_{session_timestamp}.log\", \"w\", encoding=\"utf-8\"\n",
    "    ) as log_file:\n",
    "        # Iterate through each search term\n",
    "        for search_term in COMMON_SEARCH_TERMS:\n",
    "            log_file.write(\n",
    "                f\"\\n{'='*50}\\nProcessing search term: {search_term}\\n{'='*50}\\n\"\n",
    "            )\n",
    "            print(f\"\\n{'='*50}\\nProcessing search term: {search_term}\\n{'='*50}\")\n",
    "\n",
    "            # Iterate through each country\n",
    "            for country in glassdoor_links_map.keys():\n",
    "                message = (\n",
    "                    f\"\\nScraping Glassdoor jobs for {country} - Search: {search_term}\"\n",
    "                )\n",
    "                print(message)\n",
    "                log_file.write(message + \"\\n\")\n",
    "\n",
    "                try:\n",
    "                    jobs = scrape_glassdoor_jobs(\n",
    "                        search_term, country, jobs_per_country=JOBS_PER_COUNTRY\n",
    "                    )\n",
    "\n",
    "                    message = f\"Successfully scraped {len(jobs)} jobs from {country} for {search_term}\"\n",
    "                    print(message)\n",
    "                    log_file.write(message + \"\\n\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    error_message = (\n",
    "                        f\"Error scraping {country} for {search_term}: {str(e)}\"\n",
    "                    )\n",
    "                    print(error_message)\n",
    "                    log_file.write(error_message + \"\\n\")\n",
    "\n",
    "                # Add a minimal delay between countries\n",
    "                time.sleep(uniform(0.1, 0.5))\n",
    "\n",
    "            # Add a minimal delay between search terms\n",
    "            time.sleep(uniform(0.1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data Analysis\n",
    "This cell performs basic exploratory data analysis on the scraped data:\n",
    "- Basic dataset information and statistics\n",
    "- Missing value analysis\n",
    "- Duplicate detection\n",
    "- Value distributions\n",
    "- Data quality checks\n",
    "- Token usage analysis for API cost estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading glassdoor.csv...\n",
      "\n",
      "=== BASIC INFORMATION ===\n",
      "Total number of rows: 3513\n",
      "Total number of columns: 7\n",
      "\n",
      "Columns: ['query', 'country', 'job_description', 'location', 'salary', 'job_title', 'job_link']\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "           Missing Count  Missing Percentage\n",
      "job_title              4                0.11\n",
      "\n",
      "=== DUPLICATES ===\n",
      "Total duplicate rows: 0\n",
      "Rows with duplicate job links: 0\n",
      "\n",
      "=== VALUE DISTRIBUTIONS ===\n",
      "\n",
      "Country distribution:\n",
      "country\n",
      "US    1229\n",
      "IN    1178\n",
      "SG    1106\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 10 job titles:\n",
      "job_title\n",
      "Data Scientist          54\n",
      "DevOps Engineer         47\n",
      "Data Analyst            45\n",
      "Software Engineer       45\n",
      "Data Engineer           40\n",
      "Scrum Master            38\n",
      "Software Developer      37\n",
      "Network Engineer        37\n",
      "Full Stack Developer    31\n",
      "Business Analyst        29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== POTENTIAL DATA QUALITY ISSUES ===\n",
      "\n",
      "Jobs with very short descriptions (<100 chars): 12\n",
      "Jobs with potentially invalid salaries: 69\n",
      "\n",
      "Unique locations found:\n",
      "location\n",
      "Singapore            832\n",
      "Bengaluru            231\n",
      "Remote               178\n",
      "Pune                  82\n",
      "Hyderbd             72\n",
      "United States         56\n",
      "Gurgaon               49\n",
      "Mumbai                33\n",
      "Queenstown Estate     31\n",
      "Chennai               29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved 85 problematic entries to 'problematic_entries.csv'\n",
      "\n",
      "=== TOKEN USAGE ANALYSIS ===\n",
      "\n",
      "Template tokens (per request): 167\n",
      "\n",
      "=== TOTAL TOKEN USAGE AND COST ===\n",
      "Total Input Tokens: 2654369\n",
      "Total Output Tokens: 333735\n",
      "Input Cost: $39.8155\n",
      "Output Cost: $25.0301\n",
      "Total Cost: $64.8457\n"
     ]
    }
   ],
   "source": [
    "def analyze_glassdoor_data():\n",
    "    # Read the CSV file\n",
    "    print(\"\\nReading glassdoor.csv...\")\n",
    "    df = pd.read_csv(\"glassdoor.csv\")\n",
    "\n",
    "    # Basic information about the dataset\n",
    "    print(\"\\n=== BASIC INFORMATION ===\")\n",
    "    print(f\"Total number of rows: {len(df)}\")\n",
    "    print(f\"Total number of columns: {len(df.columns)}\")\n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "    # Check for missing values\n",
    "    print(\"\\n=== MISSING VALUES ===\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentages = (missing_values / len(df)) * 100\n",
    "    missing_info = pd.DataFrame(\n",
    "        {\n",
    "            \"Missing Count\": missing_values,\n",
    "            \"Missing Percentage\": missing_percentages.round(2),\n",
    "        }\n",
    "    )\n",
    "    print(missing_info[missing_info[\"Missing Count\"] > 0])\n",
    "\n",
    "    # Check for duplicates\n",
    "    print(\"\\n=== DUPLICATES ===\")\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"Total duplicate rows: {duplicates}\")\n",
    "\n",
    "    # Check for duplicate job links (same job posted multiple times)\n",
    "    duplicate_links = df[df.duplicated(subset=[\"job_link\"], keep=False)]\n",
    "    print(f\"Rows with duplicate job links: {len(duplicate_links)}\")\n",
    "\n",
    "    # Value distributions\n",
    "    print(\"\\n=== VALUE DISTRIBUTIONS ===\")\n",
    "    print(\"\\nCountry distribution:\")\n",
    "    print(df[\"country\"].value_counts())\n",
    "\n",
    "    print(\"\\nTop 10 job titles:\")\n",
    "    print(df[\"job_title\"].value_counts().head(10))\n",
    "\n",
    "    # Check for potential data quality issues\n",
    "    print(\"\\n=== POTENTIAL DATA QUALITY ISSUES ===\")\n",
    "\n",
    "    # Check for very short or empty descriptions\n",
    "    short_desc = df[df[\"job_description\"].str.len() < 100]\n",
    "    print(f\"\\nJobs with very short descriptions (<100 chars): {len(short_desc)}\")\n",
    "\n",
    "    # Check for invalid salaries (if they don't contain numbers)\n",
    "    invalid_salaries = df[~df[\"salary\"].str.contains(r\"\\d\", na=True)]\n",
    "    print(f\"Jobs with potentially invalid salaries: {len(invalid_salaries)}\")\n",
    "\n",
    "    # Check for unusual locations\n",
    "    print(\"\\nUnique locations found:\")\n",
    "    print(df[\"location\"].value_counts().head(10))\n",
    "\n",
    "    # Save problematic entries to a separate CSV for review\n",
    "    problematic = df[\n",
    "        (df.isnull().any(axis=1))  # Any missing values\n",
    "        | (df.duplicated())  # Duplicates\n",
    "        | (df[\"job_description\"].str.len() < 100)  # Short descriptions\n",
    "        | (~df[\"salary\"].str.contains(r\"\\d\", na=True))  # Invalid salaries\n",
    "    ]\n",
    "\n",
    "    if len(problematic) > 0:\n",
    "        problematic.to_csv(\"problematic_entries.csv\", index=False)\n",
    "        print(\n",
    "            f\"\\nSaved {len(problematic)} problematic entries to 'problematic_entries.csv'\"\n",
    "        )\n",
    "\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count tokens using tiktoken\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")  # Claude's encoding\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def calculate_claude_cost(input_tokens: int, output_tokens: int) -> Dict[str, float]:\n",
    "    \"\"\"Calculate Claude API cost based on token usage\"\"\"\n",
    "    input_cost_per_1k = 0.015\n",
    "    output_cost_per_1k = 0.075\n",
    "\n",
    "    input_cost = (input_tokens / 1000) * input_cost_per_1k\n",
    "    output_cost = (output_tokens / 1000) * output_cost_per_1k\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    return {\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens,\n",
    "        \"input_cost\": round(input_cost, 4),\n",
    "        \"output_cost\": round(output_cost, 4),\n",
    "        \"total_cost\": round(total_cost, 4),\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_token_usage():\n",
    "    \"\"\"Analyze token usage and cost for EDA processing\"\"\"\n",
    "    print(\"\\n=== TOKEN USAGE ANALYSIS ===\")\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(\"glassdoor.csv\")\n",
    "\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "\n",
    "    # Template tokens (counted once)\n",
    "    template = \"\"\"Analyze this job posting and extract the following features in JSON format:\n",
    "        - soft_skills: List of soft skills mentioned (communication, leadership, etc)\n",
    "        - hard_skills: List of technical skills, tools, languages required\n",
    "        - location_flexibility: One of [remote, hybrid, onsite, unspecified]\n",
    "        - contract_type: One of [full-time, part-time, contract, internship, unspecified] \n",
    "        - education_level: Minimum required education level [high_school, bachelors, masters, phd, unspecified]\n",
    "        - field_of_study: Required field of study or major\n",
    "        - min_years_experience: Minimum years of experience required (numeric, -1 if unspecified)\n",
    "        - salary_range: Extract salary range if available [min, max, currency, period(yearly/monthly/hourly)]\"\"\"\n",
    "\n",
    "    template_tokens = count_tokens(template)\n",
    "    print(f\"\\nTemplate tokens (per request): {template_tokens}\")\n",
    "\n",
    "    # Analyze each job\n",
    "    for _, row in df.iterrows():\n",
    "        prompt_text = f\"\"\"\n",
    "        Job Title: {row['job_title']}\n",
    "        Location: {row['location']}\n",
    "        Salary: {row['salary']}\n",
    "        Description: {row['job_description']}\n",
    "        \"\"\"\n",
    "\n",
    "        input_tokens = template_tokens + count_tokens(prompt_text)\n",
    "        total_input_tokens += input_tokens\n",
    "\n",
    "        # Estimate output tokens based on typical JSON response\n",
    "        sample_output = {\n",
    "            \"soft_skills\": [\"communication\", \"teamwork\"],\n",
    "            \"hard_skills\": [\"python\", \"sql\"],\n",
    "            \"location_flexibility\": \"remote\",\n",
    "            \"contract_type\": \"full-time\",\n",
    "            \"education_level\": \"bachelors\",\n",
    "            \"field_of_study\": \"computer science\",\n",
    "            \"min_years_experience\": 3,\n",
    "            \"salary_range\": {\n",
    "                \"min\": 80000,\n",
    "                \"max\": 120000,\n",
    "                \"currency\": \"USD\",\n",
    "                \"period\": \"yearly\",\n",
    "            },\n",
    "        }\n",
    "        output_tokens = count_tokens(json.dumps(sample_output))\n",
    "        total_output_tokens += output_tokens\n",
    "\n",
    "    # Calculate total cost\n",
    "    cost_analysis = calculate_claude_cost(total_input_tokens, total_output_tokens)\n",
    "\n",
    "    print(\"\\n=== TOTAL TOKEN USAGE AND COST ===\")\n",
    "    print(f\"Total Input Tokens: {cost_analysis['input_tokens']}\")\n",
    "    print(f\"Total Output Tokens: {cost_analysis['output_tokens']}\")\n",
    "    print(f\"Input Cost: ${cost_analysis['input_cost']}\")\n",
    "    print(f\"Output Cost: ${cost_analysis['output_cost']}\")\n",
    "    print(f\"Total Cost: ${cost_analysis['total_cost']}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_glassdoor_data()\n",
    "    analyze_token_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction with Google's Gemini AI\n",
    "This cell implements automated feature extraction from job descriptions using Google's Gemini AI:\n",
    "- Extracts soft skills, hard skills, location flexibility\n",
    "- Identifies contract type and education requirements\n",
    "- Determines experience requirements and salary ranges\n",
    "- Handles incremental processing and saves results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 existing processed rows in eda.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                    | 19/3513 [00:50<2:57:34,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                    | 20/3513 [01:00<5:03:23,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                    | 21/3513 [01:08<6:00:34,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                    | 31/3513 [01:44<2:38:24,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                    | 32/3513 [01:55<4:57:22,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting features: 429 Resource has been exhausted (e.g. check quota).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                   | 35/3513 [02:03<3:23:53,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                   | 36/3513 [02:14<5:27:51,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting features: 429 Resource has been exhausted (e.g. check quota).\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                   | 45/3513 [02:42<2:50:51,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                   | 46/3513 [02:53<5:09:48,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting features: 429 Resource has been exhausted (e.g. check quota).\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|                                                                                                                   | 48/3513 [03:04<5:02:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n",
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 2/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|                                                                                                                   | 60/3513 [03:44<2:35:49,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rate limit hit. Sleeping for 5 seconds... (Attempt 1/3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|                                                                                                                   | 60/3513 [03:47<3:37:45,  3.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 63\u001b[0m, in \u001b[0;36mJobFeatureExtractor.extract_features\u001b[0;34m(self, description)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerationConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# If successful, break out of the retry loop\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 192\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;66;03m# Append to CSV immediately\u001b[39;00m\n\u001b[1;32m    189\u001b[0m         current_result\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meda.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39mmode, header\u001b[38;5;241m=\u001b[39mheader, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 192\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 178\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124mJob Title: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124mLocation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124mSalary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_description\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Extract features for current job\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Create a new DataFrame with both the original row and features\u001b[39;00m\n\u001b[1;32m    181\u001b[0m combined_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrow\u001b[38;5;241m.\u001b[39mto_dict(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfeatures}\n",
      "Cell \u001b[0;32mIn[7], line 81\u001b[0m, in \u001b[0;36mJobFeatureExtractor.extract_features\u001b[0;34m(self, description)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_retry \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     79\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRate limit hit. Sleeping for 5 seconds... (Attempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_retry\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m         )\n\u001b[0;32m---> 81\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# Re-raise the exception if we've exhausted retries or it's a different error\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class JobFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "\n",
    "    def extract_features(self, description: str) -> Dict:\n",
    "        \"\"\"Extract features from job description using Gemini\"\"\"\n",
    "        import time\n",
    "\n",
    "        # Default empty response structure\n",
    "        default_response = {\n",
    "            \"soft_skills\": [],\n",
    "            \"hard_skills\": [],\n",
    "            \"location_flexibility\": \"unspecified\",\n",
    "            \"contract_type\": \"unspecified\",\n",
    "            \"education_level\": \"unspecified\",\n",
    "            \"field_of_study\": \"unspecified\",\n",
    "            \"min_years_experience\": -1,\n",
    "            \"salary_range\": {\n",
    "                \"min\": -1,\n",
    "                \"max\": -1,\n",
    "                \"currency\": \"unspecified\",\n",
    "                \"period\": \"unspecified\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "        prompt = f\"\"\"You are a JSON generator. Your task is to analyze this job posting and return ONLY a valid JSON object with no additional text or formatting. Extract the following features:\n",
    "        - soft_skills: List of soft skills mentioned (communication, leadership, etc)\n",
    "        - hard_skills: List of technical skills, tools, languages required\n",
    "        - location_flexibility: One of [remote, hybrid, onsite, unspecified]\n",
    "        - contract_type: One of [full-time, part-time, contract, internship, unspecified] \n",
    "        - education_level: Minimum required education level [high_school, bachelors, masters, phd, unspecified]\n",
    "        - field_of_study: Required field of study or major\n",
    "        - min_years_experience: Minimum years of experience required (numeric, -1 if unspecified)\n",
    "        - salary_range: Extract salary range if available [min, max, currency, period(yearly/monthly/hourly)]\n",
    "        \n",
    "        Job Details:\n",
    "        {description}\n",
    "\n",
    "        IMPORTANT: Return ONLY a valid JSON object. No other text, no markdown formatting, no explanations.\n",
    "        Example format:\n",
    "        {{\"soft_skills\": [\"communication\"], \"hard_skills\": [\"python\"], \"location_flexibility\": \"remote\", \"contract_type\": \"full-time\", \"education_level\": \"bachelors\", \"field_of_study\": \"computer science\", \"min_years_experience\": 3, \"salary_range\": {{\"min\": 80000, \"max\": 100000, \"currency\": \"USD\", \"period\": \"yearly\"}}}}\n",
    "        \"\"\"\n",
    "\n",
    "        max_retries = 5\n",
    "        current_retry = 0\n",
    "\n",
    "        try:\n",
    "            while current_retry < max_retries:\n",
    "                try:\n",
    "                    response = self.model.generate_content(\n",
    "                        prompt,\n",
    "                        generation_config=genai.types.GenerationConfig(\n",
    "                            temperature=0,\n",
    "                            top_p=1,\n",
    "                            top_k=1,\n",
    "                            max_output_tokens=1024,\n",
    "                        ),\n",
    "                    )\n",
    "                    break  # If successful, break out of the retry loop\n",
    "\n",
    "                except Exception as e:\n",
    "                    if \"429\" in str(e):  # Rate limit error\n",
    "                        current_retry += 1\n",
    "                        if current_retry < max_retries:\n",
    "                            print(\n",
    "                                f\"\\nRate limit hit. Sleeping for 5 seconds... (Attempt {current_retry}/{max_retries})\"\n",
    "                            )\n",
    "                            time.sleep(5)\n",
    "                            continue\n",
    "                    raise  # Re-raise the exception if we've exhausted retries or it's a different error\n",
    "\n",
    "            # Clean and extract JSON from response\n",
    "            response_text = response.text.strip()\n",
    "\n",
    "            # Try to find JSON content if wrapped in other text\n",
    "            try:\n",
    "                # First attempt: direct JSON parse\n",
    "                features = json.loads(response_text)\n",
    "            except json.JSONDecodeError:\n",
    "                # Second attempt: try to find JSON-like structure\n",
    "                start_idx = response_text.find(\"{\")\n",
    "                end_idx = response_text.rfind(\"}\")\n",
    "                if start_idx != -1 and end_idx != -1:\n",
    "                    json_str = response_text[start_idx : end_idx + 1]\n",
    "                    try:\n",
    "                        features = json.loads(json_str)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Failed to parse JSON: {json_str}\")\n",
    "                        return default_response\n",
    "                else:\n",
    "                    print(\"Could not find valid JSON in response\")\n",
    "                    return default_response\n",
    "\n",
    "            # Ensure all required fields are present\n",
    "            for key in default_response.keys():\n",
    "                if key not in features:\n",
    "                    features[key] = default_response[key]\n",
    "\n",
    "            return features\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features: {str(e)}\")\n",
    "            return default_response\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Read both CSV files\n",
    "    glassdoor_df = pd.read_csv(\"glassdoor.csv\")\n",
    "\n",
    "    try:\n",
    "        existing_eda_df = pd.read_csv(\"eda.csv\")\n",
    "        # Get the number of rows already processed\n",
    "        processed_rows = len(existing_eda_df)\n",
    "        print(f\"Found {processed_rows} existing processed rows in eda.csv\")\n",
    "\n",
    "        # Get the remaining rows from glassdoor.csv\n",
    "        df = glassdoor_df.iloc[processed_rows:]\n",
    "\n",
    "        if len(df) == 0:\n",
    "            print(\"All rows have been processed already!\")\n",
    "            return\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"No existing eda.csv found. Creating new eda.csv file...\")\n",
    "        df = glassdoor_df\n",
    "        existing_eda_df = None\n",
    "        # Create empty eda.csv with headers\n",
    "        empty_df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"query\",\n",
    "                \"country\",\n",
    "                \"job_description\",\n",
    "                \"location\",\n",
    "                \"salary\",\n",
    "                \"job_title\",\n",
    "                \"job_link\",\n",
    "                \"soft_skills\",\n",
    "                \"hard_skills\",\n",
    "                \"location_flexibility\",\n",
    "                \"contract_type\",\n",
    "                \"educational_level\",\n",
    "                \"field_of_study\",\n",
    "                \"min_years_of_experience\",\n",
    "                \"salary_range\",\n",
    "            ]\n",
    "        )\n",
    "        empty_df.to_csv(\"eda.csv\", index=False)\n",
    "        print(\"Created empty eda.csv with headers\")\n",
    "\n",
    "    # Initialize feature extractor\n",
    "    extractor = JobFeatureExtractor()\n",
    "\n",
    "    # Reset index of remaining rows to process\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Process each job and append immediately to CSV\n",
    "    total_rows = len(df)\n",
    "    for idx, row in tqdm(df.iterrows(), desc=\"Extracting features\", total=total_rows):\n",
    "        prompt_text = f\"\"\"\n",
    "        Job Title: {row['job_title']}\n",
    "        Location: {row['location']}\n",
    "        Salary: {row['salary']}\n",
    "        Description: {row['job_description']}\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract features for current job\n",
    "        features = extractor.extract_features(prompt_text)\n",
    "\n",
    "        # Create a new DataFrame with both the original row and features\n",
    "        combined_data = {**row.to_dict(), **features}\n",
    "        current_result = pd.DataFrame([combined_data])\n",
    "\n",
    "        # Append mode if not first row, write mode if first row\n",
    "        mode = \"a\" if idx > 0 or existing_eda_df is not None else \"w\"\n",
    "        header = not (mode == \"a\")  # Only write header for first row\n",
    "\n",
    "        # Append to CSV immediately\n",
    "        current_result.to_csv(\"eda.csv\", mode=mode, header=header, index=False)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated EDA Report Generation\n",
    "This final cell generates a comprehensive exploratory data analysis report:\n",
    "- Creates an interactive HTML report using ydata-profiling\n",
    "- Includes statistical analysis and visualizations\n",
    "- Shows correlations between different job features\n",
    "- Provides insights into the job market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jukit_cell_id": "0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading eda.csv file...\n",
      "Generating profile report...\n",
      "Saving report to jobs_analysis_report.html...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23b2bba49a346e4a7e66b98b6e63842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6cc6d07ebc4c05a2a62aedbeecdc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0d9d3f0f334d4da15ed7dad93c660a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179a70f81c7c46d6a4a715e36110025b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report generation complete!\n"
     ]
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def generate_profile_report():\n",
    "    print(\"Reading eda.csv file...\")\n",
    "    df = pd.read_csv(\"eda.csv\")\n",
    "\n",
    "    print(\"Generating profile report...\")\n",
    "    profile = ProfileReport(\n",
    "        df,\n",
    "        title=\"Glassdoor Jobs Analysis Report\",\n",
    "        explorative=True,\n",
    "        correlations={\n",
    "            \"auto\": {\"calculate\": True},\n",
    "            \"pearson\": {\"calculate\": True},\n",
    "            \"spearman\": {\"calculate\": True},\n",
    "            \"kendall\": {\"calculate\": True},\n",
    "            \"phi_k\": {\"calculate\": True},\n",
    "            \"cramers\": {\"calculate\": True},\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"Saving report to jobs_analysis_report.html...\")\n",
    "    profile.to_file(\"eda_analysis_report.html\")\n",
    "    print(\"Report generation complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_profile_report()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
